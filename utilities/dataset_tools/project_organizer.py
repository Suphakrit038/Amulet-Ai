#!/usr/bin/env python3
"""
üßπ Project Structure Cleanup & Organization Tool
‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
"""
import os
import shutil
import json
from pathlib import Path
from datetime import datetime
import glob

class ProjectOrganizer:
    def __init__(self, project_root="E:/Amulet-Ai"):
        self.project_root = Path(project_root)
        self.cleanup_report = {
            "timestamp": datetime.now().isoformat(),
            "actions": [],
            "files_moved": 0,
            "files_deleted": 0,
            "folders_created": 0
        }
        
    def analyze_root_files(self):
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå root"""
        print("üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå root...")
        
        root_files = []
        for item in self.project_root.iterdir():
            if item.is_file():
                root_files.append({
                    "name": item.name,
                    "size": item.stat().st_size,
                    "extension": item.suffix,
                    "path": str(item)
                })
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
        file_categories = {
            "scripts": [],      # Python scripts
            "configs": [],      # Configuration files
            "docs": [],         # Documentation
            "tests": [],        # Test files
            "temp": [],         # Temporary files
            "models": [],       # Model files
            "datasets": [],     # Dataset files
            "reports": [],      # Report files
            "keep_root": []     # ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô root
        }
        
        for file_info in root_files:
            name = file_info["name"].lower()
            ext = file_info["extension"].lower()
            
            # ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô root
            if name in ["readme.md", "requirements.txt", "makefile", ".gitignore", ".env.example"]:
                file_categories["keep_root"].append(file_info)
            
            # Python scripts
            elif ext == ".py":
                if "test" in name:
                    file_categories["tests"].append(file_info)
                elif name in ["dataset_organizer.py", "phase1_dataset_organizer.py", 
                             "phase2_preprocessing.py", "phase3_model_training.py"]:
                    file_categories["scripts"].append(file_info)
                elif "train" in name or "model" in name:
                    file_categories["scripts"].append(file_info)
                else:
                    file_categories["scripts"].append(file_info)
            
            # Documentation
            elif ext == ".md":
                file_categories["docs"].append(file_info)
            
            # Configuration
            elif ext in [".json", ".yaml", ".yml", ".ini", ".cfg"]:
                file_categories["configs"].append(file_info)
            
            # Temporary files
            elif "temp" in name or "tmp" in name or ext in [".log", ".cache"]:
                file_categories["temp"].append(file_info)
            
            # Reports
            elif "report" in name or "analysis" in name or "result" in name:
                file_categories["reports"].append(file_info)
            
            # Models
            elif ext in [".joblib", ".pkl", ".model"]:
                file_categories["models"].append(file_info)
        
        return file_categories
    
    def create_organized_structure(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà"""
        print("\nüèóÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà...")
        
        new_folders = [
            "archive/scripts",
            "archive/old_models", 
            "archive/temp_files",
            "documentation/reports",
            "documentation/analysis",
            "configuration",
            "utilities/dataset_tools",
            "utilities/testing",
            "backup/models",
            "backup/configs"
        ]
        
        for folder in new_folders:
            folder_path = self.project_root / folder
            if not folder_path.exists():
                folder_path.mkdir(parents=True, exist_ok=True)
                self.cleanup_report["folders_created"] += 1
                print(f"   ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á: {folder}")
        
        return new_folders
    
    def move_files_to_organized_structure(self, file_categories):
        """‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà"""
        print("\nüì¶ ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà...")
        
        # Mapping ‡∏Å‡∏≤‡∏£‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
        move_mapping = {
            "scripts": "utilities/dataset_tools",
            "tests": "utilities/testing", 
            "docs": "documentation/reports",
            "configs": "configuration",
            "temp": "archive/temp_files",
            "reports": "documentation/analysis"
        }
        
        for category, files in file_categories.items():
            if category in move_mapping and files:
                target_folder = self.project_root / move_mapping[category]
                
                print(f"\n   üìÅ ‡∏¢‡πâ‡∏≤‡∏¢ {category} ({len(files)} ‡πÑ‡∏ü‡∏•‡πå)")
                for file_info in files:
                    source = Path(file_info["path"])
                    target = target_folder / source.name
                    
                    try:
                        if source.exists() and source != target:
                            shutil.move(str(source), str(target))
                            print(f"      ‚úÖ {source.name} ‚Üí {move_mapping[category]}")
                            self.cleanup_report["files_moved"] += 1
                            self.cleanup_report["actions"].append({
                                "action": "move",
                                "file": source.name,
                                "from": "root",
                                "to": move_mapping[category]
                            })
                    except Exception as e:
                        print(f"      ‚ùå Error moving {source.name}: {e}")
    
    def handle_duplicate_folders(self):
        """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô"""
        print("\nüîÑ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô...")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô
        potential_duplicates = [
            ("Data set", "organized_dataset"),
            ("trained_model_backup", "backup/models")
        ]
        
        for old_folder, suggested_location in potential_duplicates:
            old_path = self.project_root / old_folder
            if old_path.exists():
                print(f"   üìÅ ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö: {old_folder}")
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå archive ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏¢‡πâ‡∏≤‡∏¢
                archive_path = self.project_root / "archive" / old_folder.replace(" ", "_")
                if not archive_path.exists():
                    archive_path.mkdir(parents=True, exist_ok=True)
                
                try:
                    shutil.move(str(old_path), str(archive_path))
                    print(f"      ‚úÖ ‡∏¢‡πâ‡∏≤‡∏¢ {old_folder} ‚Üí archive/")
                    self.cleanup_report["actions"].append({
                        "action": "archive",
                        "folder": old_folder,
                        "to": f"archive/{old_folder.replace(' ', '_')}"
                    })
                except Exception as e:
                    print(f"      ‚ùå Error: {e}")
    
    def clean_redundant_files(self):
        """‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
        print("\nüóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô...")
        
        # ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô
        redundant_patterns = [
            "*_backup_*.py",
            "*_old.py", 
            "*_temp.py",
            "*.tmp",
            "*.cache",
            "__pycache__"
        ]
        
        for pattern in redundant_patterns:
            files = list(self.project_root.glob(pattern))
            for file_path in files:
                if file_path.is_file():
                    try:
                        file_path.unlink()
                        print(f"   üóëÔ∏è ‡∏•‡∏ö: {file_path.name}")
                        self.cleanup_report["files_deleted"] += 1
                        self.cleanup_report["actions"].append({
                            "action": "delete",
                            "file": file_path.name,
                            "reason": "redundant"
                        })
                    except Exception as e:
                        print(f"   ‚ùå Error deleting {file_path.name}: {e}")
    
    def create_project_structure_doc(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå"""
        print("\nüìã ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå...")
        
        structure_doc = """# üèóÔ∏è Amulet-AI Project Structure

## üìÅ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡πÅ‡∏•‡πâ‡∏ß

```
Amulet-AI/
‚îú‚îÄ‚îÄ üì± ai_models/              # AI Models & Machine Learning
‚îÇ   ‚îú‚îÄ‚îÄ compatibility_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_production_system.py
‚îÇ   ‚îî‚îÄ‚îÄ labels.json
‚îÇ
‚îú‚îÄ‚îÄ üåê api/                    # API Backend Services
‚îÇ   ‚îú‚îÄ‚îÄ main_api.py           # Main API
‚îÇ   ‚îú‚îÄ‚îÄ main_api_fast.py      # FastAPI version
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ üñ•Ô∏è frontend/              # User Interface
‚îÇ   ‚îú‚îÄ‚îÄ main_streamlit_app.py # Main UI
‚îÇ   ‚îú‚îÄ‚îÄ components/           # UI Components
‚îÇ   ‚îî‚îÄ‚îÄ utils/               # UI Utilities
‚îÇ
‚îú‚îÄ‚îÄ ‚öôÔ∏è core/                  # Core System Components
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ security.py          # Security features
‚îÇ   ‚îî‚îÄ‚îÄ performance.py       # Performance monitoring
‚îÇ
‚îú‚îÄ‚îÄ üìä organized_dataset/      # Organized Training Data
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # Raw images
‚îÇ   ‚îú‚îÄ‚îÄ processed/           # Processed images
‚îÇ   ‚îú‚îÄ‚îÄ augmented/           # Augmented data
‚îÇ   ‚îú‚îÄ‚îÄ splits/              # Train/Val/Test splits
‚îÇ   ‚îî‚îÄ‚îÄ metadata/            # Dataset metadata
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ trained_model/         # Active Model Files
‚îÇ   ‚îú‚îÄ‚îÄ classifier.joblib    # Trained classifier
‚îÇ   ‚îú‚îÄ‚îÄ scaler.joblib        # Feature scaler
‚îÇ   ‚îú‚îÄ‚îÄ label_encoder.joblib # Label encoder
‚îÇ   ‚îî‚îÄ‚îÄ model_info.json      # Model metadata
‚îÇ
‚îú‚îÄ‚îÄ üß™ tests/                 # Testing Suite
‚îÇ   ‚îú‚îÄ‚îÄ comprehensive_test_suite.py
‚îÇ   ‚îî‚îÄ‚îÄ system_analyzer.py
‚îÇ
‚îú‚îÄ‚îÄ üìö documentation/         # Project Documentation
‚îÇ   ‚îú‚îÄ‚îÄ reports/             # Analysis reports
‚îÇ   ‚îî‚îÄ‚îÄ analysis/            # Technical analysis
‚îÇ
‚îú‚îÄ‚îÄ üîß utilities/             # Utility Scripts
‚îÇ   ‚îú‚îÄ‚îÄ dataset_tools/       # Dataset management
‚îÇ   ‚îî‚îÄ‚îÄ testing/             # Testing utilities
‚îÇ
‚îú‚îÄ‚îÄ üöÄ deployment/            # Deployment Configuration
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.*.yml
‚îÇ   ‚îî‚îÄ‚îÄ deployment configs
‚îÇ
‚îú‚îÄ‚îÄ üìã configuration/         # Configuration Files
‚îÇ   ‚îî‚îÄ‚îÄ config files
‚îÇ
‚îú‚îÄ‚îÄ üì¶ archive/               # Archived Files
‚îÇ   ‚îú‚îÄ‚îÄ scripts/             # Old scripts
‚îÇ   ‚îú‚îÄ‚îÄ temp_files/          # Temporary files
‚îÇ   ‚îî‚îÄ‚îÄ old_models/          # Backup models
‚îÇ
‚îî‚îÄ‚îÄ üìÑ ROOT FILES             # Essential Project Files
    ‚îú‚îÄ‚îÄ README.md            # Project documentation
    ‚îú‚îÄ‚îÄ requirements.txt     # Dependencies
    ‚îú‚îÄ‚îÄ Makefile            # Build automation
    ‚îî‚îÄ‚îÄ .gitignore          # Git ignore rules
```

## üéØ ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå

### ü§ñ AI Models
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ML
- **‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ:** scikit-learn, OpenCV, NumPy
- **‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß, label mappings

### üåê API Backend
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ REST API ‡πÅ‡∏•‡∏∞ business logic
- **‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ:** FastAPI, Uvicorn
- **‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå:** Image upload, prediction, health checks

### üñ•Ô∏è Frontend
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** User Interface ‡πÅ‡∏•‡∏∞ User Experience
- **‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ:** Streamlit, HTML/CSS
- **‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå:** File upload, result display, interactive UI

### ‚öôÔ∏è Core System
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** Core utilities ‡πÅ‡∏•‡∏∞ system management
- **‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ:** Python utilities
- **‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå:** Configuration, security, performance monitoring

### üìä Dataset Management
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö
- **‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ:** OpenCV, PIL
- **‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå:** Data preprocessing, augmentation, organization

## üîÑ Workflow ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

1. **Data Flow:** Raw Images ‚Üí Processing ‚Üí Augmentation ‚Üí Training
2. **Model Flow:** Training ‚Üí Validation ‚Üí Testing ‚Üí Deployment
3. **API Flow:** Request ‚Üí Processing ‚Üí Prediction ‚Üí Response
4. **User Flow:** Upload ‚Üí Display ‚Üí Results ‚Üí Export

## üõ†Ô∏è ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•„Ç∏‡∏µ‡∏™‡πÅ‡∏ï‡∏Å

- **Backend:** Python 3.13, FastAPI, scikit-learn
- **Frontend:** Streamlit, HTML/CSS
- **AI/ML:** Random Forest, OpenCV, NumPy
- **Data:** JSON, Joblib, File System
- **DevOps:** Docker (planned), Git

---
**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠:** {timestamp}
**‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** 3.0
**‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:** ‚úÖ Organized
""".format(timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        
        doc_path = self.project_root / "documentation" / "PROJECT_STRUCTURE.md"
        doc_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(doc_path, 'w', encoding='utf-8') as f:
            f.write(structure_doc)
        
        print(f"   ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: {doc_path}")
    
    def save_cleanup_report(self):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö"""
        report_path = self.project_root / "documentation" / "analysis" / "cleanup_report.json"
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.cleanup_report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìã ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô: {report_path}")
    
    def run_full_cleanup(self):
        """‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        print("üßπ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå...")
        print("=" * 60)
        
        # Step 1: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå root
        file_categories = self.analyze_root_files()
        
        # Step 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        self.create_organized_structure()
        
        # Step 3: ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
        self.move_files_to_organized_structure(file_categories)
        
        # Step 4: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô
        self.handle_duplicate_folders()
        
        # Step 5: ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        self.clean_redundant_files()
        
        # Step 6: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
        self.create_project_structure_doc()
        
        # Step 7: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
        self.save_cleanup_report()
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
        print("\n" + "=" * 60)
        print("‚úÖ ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
        print(f"üìÅ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà: {self.cleanup_report['folders_created']}")
        print(f"üì¶ ‡πÑ‡∏ü‡∏•‡πå‡∏¢‡πâ‡∏≤‡∏¢: {self.cleanup_report['files_moved']}")
        print(f"üóëÔ∏è ‡πÑ‡∏ü‡∏•‡πå‡∏•‡∏ö: {self.cleanup_report['files_deleted']}")
        print(f"üìã ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(self.cleanup_report['actions'])}")

def main():
    organizer = ProjectOrganizer()
    organizer.run_full_cleanup()

if __name__ == "__main__":
    main()