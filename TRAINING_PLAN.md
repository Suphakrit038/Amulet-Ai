# üìã ‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏° Dataset ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà

**üìÖ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** October 2, 2025  
**üéØ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:** ‡∏£‡∏ß‡∏° dataset, ‡∏•‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤, ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà

---

## üóÇÔ∏è Phase 1: ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö Dataset

### **üîç Step 1.1: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô**
- ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
- ‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
- ‚úÖ ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô

**‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô:**
```
organized_dataset/
‚îú‚îÄ‚îÄ raw/main_dataset/          # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö (172 ‡πÑ‡∏ü‡∏•‡πå)
‚îú‚îÄ‚îÄ processed/                 # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• processed (172 ‡πÑ‡∏ü‡∏•‡πå)
‚îú‚îÄ‚îÄ augmented/                 # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• augmented (860+ ‡πÑ‡∏ü‡∏•‡πå)
‚îú‚îÄ‚îÄ splits/                    # ‡πÅ‡∏ö‡πà‡∏á train/val/test (1,076 ‡πÑ‡∏ü‡∏•‡πå)
‚îî‚îÄ‚îÄ DATA SET/                  # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ã‡πâ‡∏≥ (172 ‡πÑ‡∏ü‡∏•‡πå)
```

### **üßπ Step 1.2: ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô**
- ‡∏•‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `DATA SET` (‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö `raw/main_dataset/`)
- ‡∏•‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢ `back/` ‡πÅ‡∏•‡∏∞ `front/` ‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á
- ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å `processed/` ‡πÅ‡∏•‡∏∞ `augmented/` ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö

### **üìÅ Step 1.3: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset ‡πÉ‡∏´‡∏°‡πà**
```
final_dataset/
‚îú‚îÄ‚îÄ train/                     # 751 ‡πÑ‡∏ü‡∏•‡πå (70%)
‚îÇ   ‚îú‚îÄ‚îÄ phra_sivali/
‚îÇ   ‚îú‚îÄ‚îÄ portrait_back/
‚îÇ   ‚îú‚îÄ‚îÄ prok_bodhi_9_leaves/
‚îÇ   ‚îú‚îÄ‚îÄ somdej_pratanporn_buddhagavak/
‚îÇ   ‚îú‚îÄ‚îÄ waek_man/
‚îÇ   ‚îî‚îÄ‚îÄ wat_nong_e_duk/
‚îú‚îÄ‚îÄ val/                       # 214 ‡πÑ‡∏ü‡∏•‡πå (20%)
‚îî‚îÄ‚îÄ test/                      # 111 ‡πÑ‡∏ü‡∏•‡πå (10%)
```

---

## üóëÔ∏è Phase 2: ‡∏•‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô

### **üîç Step 2.1: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤**
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `trained_model/`
- ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö

### **üóëÔ∏è Step 2.2: ‡∏•‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤**
- ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå `.pth`, `.pkl`, `.joblib`
- ‡∏•‡∏ö checkpoint ‡πÄ‡∏Å‡πà‡∏≤
- ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ config files

### **üßπ Step 2.3: ‡∏•‡πâ‡∏≤‡∏á cache ‡πÅ‡∏•‡∏∞ temporary files**
- ‡∏•‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `__pycache__/`
- ‡∏•‡∏ö log files ‡πÄ‡∏Å‡πà‡∏≤
- ‡∏•‡πâ‡∏≤‡∏á GPU memory cache

---

## ü§ñ Phase 3: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà

### **üèóÔ∏è Step 3.1: ‡∏™‡∏£‡πâ‡∏≤‡∏á Model Architecture**
- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å backbone: ResNet50 ‡∏´‡∏£‡∏∑‡∏≠ EfficientNet-B3
- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î input size: 224√ó224√ó3
- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î output classes: 6 ‡∏Ñ‡∏•‡∏≤‡∏™

### **‚ö° Fast Training Configuration**
```python
FAST_TRAINING_CONFIG = {
    'model': 'resnet50',           # ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ EfficientNet
    'input_size': (224, 224),
    'num_classes': 6,
    'batch_size': 64,              # ‡πÄ‡∏û‡∏¥‡πà‡∏° batch size
    'learning_rate': 3e-4,         # ‡πÄ‡∏û‡∏¥‡πà‡∏° learning rate
    'epochs': 25,                  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 100 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 25
    'optimizer': 'SGD',            # ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ AdamW
    'scheduler': 'StepLR',         # ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ CosineAnnealing
    'early_stopping': True,
    'patience': 5                  # ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏£‡πá‡∏ß‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
}
```

### **üöÄ Speed Optimizations:**
- ‡πÉ‡∏ä‡πâ dataset ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô `splits/`
- ‡πÉ‡∏ä‡πâ ResNet50 ‡πÅ‡∏ó‡∏ô EfficientNet (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ 2x)
- ‡∏•‡∏î epochs ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 25 ‡πÅ‡∏ó‡∏ô 100
- ‡πÄ‡∏û‡∏¥‡πà‡∏° batch size ‡πÄ‡∏õ‡πá‡∏ô 64
- ‡∏Ç‡πâ‡∏≤‡∏° hyperparameter tuning
- ‡πÉ‡∏ä‡πâ simple evaluation

### **üìä Step 3.3: ‡∏™‡∏£‡πâ‡∏≤‡∏á Data Loaders**
- ‡∏™‡∏£‡πâ‡∏≤‡∏á training transforms
- ‡∏™‡∏£‡πâ‡∏≤‡∏á validation transforms
- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î batch size ‡πÅ‡∏•‡∏∞ sampling strategy

---

## üöÄ Phase 4: ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

### **üìà Step 4.1: Initial Training**
- Baseline training (10 epochs)
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö overfitting
- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå loss curves

### **üéØ Step 4.2: Hyperparameter Tuning**
- ‡∏õ‡∏£‡∏±‡∏ö learning rate
- ‡∏õ‡∏£‡∏±‡∏ö batch size
- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö augmentation strategies

### **‚ö° Step 4.3: Full Training**
- ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏ï‡πá‡∏° 100 epochs
- ‡πÉ‡∏ä‡πâ early stopping
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å best model

### **üìä Step 4.4: Model Evaluation**
- ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ö‡∏ô test set
- ‡∏™‡∏£‡πâ‡∏≤‡∏á confusion matrix
- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì per-class metrics

---

## üìã Execution Plan (‚ö° FAST VERSION)

### **ÔøΩ Timeline (‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏•‡∏á 60%):**

**Phase 1 (10 ‡∏ô‡∏≤‡∏ó‡∏µ):**
- [x] Step 1.1: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ (‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß)
- [ ] Step 1.2: ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ + ‡∏£‡∏ß‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á (10 ‡∏ô‡∏≤‡∏ó‡∏µ) ‚ö°

**Phase 2 (5 ‡∏ô‡∏≤‡∏ó‡∏µ):**
- [ ] Step 2.1-2.3: ‡∏•‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤ + ‡∏•‡πâ‡∏≤‡∏á cache (5 ‡∏ô‡∏≤‡∏ó‡∏µ) ‚ö°

**Phase 3 (5 ‡∏ô‡∏≤‡∏ó‡∏µ):**
- [ ] Step 3.1-3.3: ‡πÉ‡∏ä‡πâ template ‡∏û‡∏£‡πâ‡∏≠‡∏° + config ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà (5 ‡∏ô‡∏≤‡∏ó‡∏µ) ‚ö°

**Phase 4 (30-45 ‡∏ô‡∏≤‡∏ó‡∏µ):**
- [ ] Step 4.1: Quick training (20-30 epochs) (20-30 ‡∏ô‡∏≤‡∏ó‡∏µ) ‚ö°
- [ ] Step 4.2: Simple evaluation (5-10 ‡∏ô‡∏≤‡∏ó‡∏µ) ‚ö°

---

## üíæ Expected Results (Fast Version)

### **üìä Dataset Summary:**
- **‡πÉ‡∏ä‡πâ dataset ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô:** `splits/` (1,076 ‡πÑ‡∏ü‡∏•‡πå)
- **Classes:** 6 ‡∏Ñ‡∏•‡∏≤‡∏™
- **Split ratio:** 70:20:10 (‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)

### **üéØ Model Performance Target (Realistic):**
- **Training Accuracy:** > 90% (‡∏•‡∏î‡∏à‡∏≤‡∏Å 95%)
- **Validation Accuracy:** > 75% (‡∏•‡∏î‡∏à‡∏≤‡∏Å 85%)
- **Test Accuracy:** > 70% (‡∏•‡∏î‡∏à‡∏≤‡∏Å 80%)
- **Training Time:** 20-30 ‡∏ô‡∏≤‡∏ó‡∏µ (‡∏•‡∏î‡∏à‡∏≤‡∏Å 60-120 ‡∏ô‡∏≤‡∏ó‡∏µ)

### **‚è±Ô∏è Total Time: 50-65 ‡∏ô‡∏≤‡∏ó‡∏µ** (‡∏•‡∏î‡∏à‡∏≤‡∏Å 2-3 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)

### **üìÅ Output Files:**
```
trained_model/
‚îú‚îÄ‚îÄ best_model.pth          # Best model weights
‚îú‚îÄ‚îÄ final_model.pth         # Final model weights
‚îú‚îÄ‚îÄ training_history.json   # Training logs
‚îú‚îÄ‚îÄ model_config.json       # Model configuration
‚îú‚îÄ‚îÄ class_mapping.json      # Class mappings
‚îî‚îÄ‚îÄ evaluation_report.json  # Performance metrics
```

---

## ‚ùì Ready to Start?

**‡∏Ñ‡∏∏‡∏ì‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏° Phase 1 ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á?**

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö "‡∏û‡∏£‡πâ‡∏≠‡∏°" ‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏ú‡∏ô‡πÉ‡∏î‡πÜ ‡πÇ‡∏õ‡∏£‡∏î‡πÅ‡∏à‡πâ‡∏á‡∏°‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö!