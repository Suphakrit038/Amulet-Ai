"""
üè∫ Amulet-AI Backend with Real Trained Model
API ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ AI Model ‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏ó‡∏ô Mock Data
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import io
import time
import base64
from datetime import datetime
import logging
import os
import sys
from pathlib import Path

# ‡πÄ‡∏û‡∏¥‡πà‡∏° backend path ‡πÄ‡∏û‡∏∑‡πà‡∏≠ import modules ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å root project
BACKEND_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(BACKEND_DIR))

try:
    # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡∏î‡∏π‡∏• models
    from models.real_model_loader import AmuletModelLoader
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á global instance
    model_loader = AmuletModelLoader()
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
    REFERENCE_IMAGES_DIR = Path(__file__).parent.parent.parent / "unified_dataset" / "reference_images"
    if not REFERENCE_IMAGES_DIR.exists():
        print(f"WARNING: Reference images directory not found: {REFERENCE_IMAGES_DIR}")
        # Fallback paths
        fallback_paths = [
            Path(__file__).parent.parent.parent / "data_base",
            Path(__file__).parent.parent.parent / "dataset_organized",
            Path(__file__).parent.parent / "reference_images",
            Path(__file__).parent.parent.parent / "ai_models" / "reference_images"
        ]
        
        for path in fallback_paths:
            if path.exists():
                REFERENCE_IMAGES_DIR = path
                print(f"‚úÖ Using fallback reference images path: {REFERENCE_IMAGES_DIR}")
                break
except ImportError as e:
    print(f"‚ö†Ô∏è Import error: {e}")
    # Fallback ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
    class DummyModelLoader:
        def __init__(self):
            self.model = None
            self.class_names = ["dummy_class"]
            self.device = "cpu"
        def initialize(self): return False
        def get_model_info(self): return {"error": "Model not loaded"}
        def predict_image(self, image_bytes): return {"success": False, "error": "No model"}
    model_loader = DummyModelLoader()

app = FastAPI(
    title="Amulet-AI with Real Trained Model", 
    description="Backend API ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ AI Model ‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß",
    version="2.0.0"
)

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á)
PRICE_DATA = {
    "somdej_fatherguay": {"min": 15000, "avg": 45000, "max": 150000},
    "somdej_portrait_back": {"min": 18000, "avg": 55000, "max": 180000},
    "somdej_prok_bodhi": {"min": 25000, "avg": 75000, "max": 250000},
    "somdej_waek_man": {"min": 20000, "avg": 60000, "max": 200000},
    "wat_nong_e_duk": {"min": 8000, "avg": 22000, "max": 70000},
    "wat_nong_e_duk_misc": {"min": 5000, "avg": 15000, "max": 50000},
}

def estimate_price(class_name: str, confidence: float):
    """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡∏≤‡∏° class ‡πÅ‡∏•‡∏∞ confidence"""
    base_prices = PRICE_DATA.get(class_name, {"min": 5000, "avg": 15000, "max": 50000})
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡∏≤‡∏° confidence
    confidence_factor = max(0.4, min(1.3, confidence * 1.2))  # 40% - 130%
    
    estimated_prices = {
        "p05": int(base_prices["min"] * confidence_factor),
        "p50": int(base_prices["avg"] * confidence_factor),
        "p95": int(base_prices["max"] * confidence_factor),
        "confidence": "high" if confidence > 0.8 else "medium" if confidence > 0.6 else "low"
    }
    
    return estimated_prices

def generate_recommendations(class_name: str, price_range: dict):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏•‡∏≤‡∏î‡∏Ç‡∏≤‡∏¢"""
    recommendations = []
    
    # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
    if "somdej" in class_name.lower():
        recommendations = [
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
                "distance": 0,
                "rating": 4.5,
                "reason": f"‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏≤‡∏¢{class_name} ‡∏°‡∏µ‡∏ú‡∏π‡πâ‡∏™‡∏∞‡∏™‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á"
            },
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡∏à‡∏ï‡∏∏‡∏à‡∏±‡∏Å‡∏£ ‡∏ã.26",
                "distance": 12,
                "rating": 4.7,
                "reason": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏ú‡∏π‡πâ‡∏ã‡∏∑‡πâ‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏π‡∏á"
            },
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ö‡∏≤‡∏á‡πÅ‡∏Ñ",
                "distance": 18,
                "rating": 4.3,
                "reason": "‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏û‡∏£‡∏∞‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"
            }
        ]
    elif "nong_e_duk" in class_name:
        recommendations = [
            {
                "market": "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á MBK",
                "distance": 8,
                "rating": 4.2,
                "reason": "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏°‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢"
            },
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
                "distance": 0,
                "rating": 4.4,
                "reason": f"‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö{class_name} ‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå"
            },
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏ô‡∏±‡∏î‡πÄ‡∏™‡∏≤‡∏£‡πå-‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå ‡∏à‡∏ï‡∏∏‡∏à‡∏±‡∏Å‡∏£",
                "distance": 15,
                "rating": 4.6,
                "reason": "‡∏ú‡∏π‡πâ‡∏ã‡∏∑‡πâ‡∏≠‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏î‡∏µ"
            }
        ]
    else:
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        recommendations = [
            {
                "market": "‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
                "distance": 0,
                "rating": 4.3,
                "reason": "‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πà‡∏ß‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å"
            },
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏≤‡∏´‡∏°‡∏ì‡πå",
                "distance": 10,
                "rating": 4.1,
                "reason": "‡∏ï‡∏•‡∏≤‡∏î‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô ‡∏ú‡∏π‡πâ‡∏ã‡∏∑‡πâ‡∏≠‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏î‡∏µ"
            },
            {
                "market": "‡∏£‡πâ‡∏≤‡∏ô‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡πà‡∏≤‡∏ô‡∏™‡∏µ‡∏•‡∏°",
                "distance": 12,
                "rating": 4.4,
                "reason": "‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏Ñ‡∏≤‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°"
            }
        ]
    
    return recommendations

def get_reference_images(class_name: str, view_type: str = None, limit: int = 3):
    """‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏"""
    reference_images = {}
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (‡πÄ‡∏ä‡πà‡∏ô somdej-fatherguay -> somdej_fatherguay)
    normalized_class_name = class_name.replace('-', '_')
    
    # ‡∏•‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πÄ‡∏£‡πá‡∏Å‡∏ó‡∏≠‡∏£‡∏µ
    class_ref_dirs = [
        REFERENCE_IMAGES_DIR / normalized_class_name,
        REFERENCE_IMAGES_DIR / class_name
    ]
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢
    thai_names = {
        "somdej_fatherguay": "‡∏û‡∏£‡∏∞‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏´‡∏•‡∏ß‡∏á‡∏û‡πà‡∏≠‡∏Å‡∏ß‡∏¢",
        "buddha_in_vihara": "‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡πÄ‡∏à‡πâ‡∏≤‡πÉ‡∏ô‡∏ß‡∏¥‡∏´‡∏≤‡∏£",
        "somdej_lion_base": "‡∏û‡∏£‡∏∞‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏ê‡∏≤‡∏ô‡∏™‡∏¥‡∏á‡∏´‡πå",
        "somdej_buddha_blessing": "‡∏û‡∏£‡∏∞‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏õ‡∏£‡∏∞‡∏ó‡∏≤‡∏ô‡∏û‡∏£ ‡∏û‡∏∏‡∏ó‡∏ò‡∏Å‡∏ß‡∏±‡∏Å",
        "somdej_portrait_back": "‡∏û‡∏£‡∏∞‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏´‡∏•‡∏±‡∏á‡∏£‡∏π‡∏õ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô",
        "phra_san": "‡∏û‡∏£‡∏∞‡∏™‡∏£‡∏£‡∏Ñ‡πå",
        "phra_sivali": "‡∏û‡∏£‡∏∞‡∏™‡∏¥‡∏ß‡∏•‡∏µ",
        "somdej_prok_bodhi": "‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏¥‡∏°‡∏û‡πå‡∏õ‡∏£‡∏Å‡πÇ‡∏û‡∏ò‡∏¥‡πå 9 ‡πÉ‡∏ö",
        "somdej_waek_man": "‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡πÅ‡∏´‡∏ß‡∏Å‡∏°‡πà‡∏≤‡∏ô",
        "wat_nong_e_duk": "‡∏≠‡∏≠‡∏Å‡∏ß‡∏±‡∏î‡∏´‡∏ô‡∏≠‡∏á‡∏≠‡∏µ‡∏î‡∏∏‡∏Å"
    }
    
    if normalized_class_name in thai_names:
        class_ref_dirs.append(REFERENCE_IMAGES_DIR / thai_names[normalized_class_name])
    
    # ‡∏î‡∏π‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡πÑ‡∏î‡πÄ‡∏£‡πá‡∏Å‡∏ó‡∏≠‡∏£‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ
    class_ref_dir = None
    for dir_path in class_ref_dirs:
        if dir_path.exists():
            class_ref_dir = dir_path
            break
            
    if not class_ref_dir:
        print(f"WARNING: Reference directory not found for class: {class_name}")
        # ‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡πÑ‡∏î‡πÄ‡∏£‡πá‡∏Å‡∏ó‡∏≠‡∏£‡∏µ
        subdirs = [d for d in REFERENCE_IMAGES_DIR.iterdir() if d.is_dir()]
        for subdir in subdirs:
            if (any(name in subdir.name.lower() for name in normalized_class_name.lower().split('_')) or
                any(name in normalized_class_name.lower() for name in subdir.name.lower().split('_'))):
                class_ref_dir = subdir
                print(f"‚úÖ Found similar reference directory: {class_ref_dir}")
                break
                
        if not class_ref_dir:
            return reference_images
    
    try:
        # ‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≤‡∏° view_type
        if view_type:
            img_files = list(class_ref_dir.glob(f"{view_type}_*.*"))[:limit]
            
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ view_type ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ view_type ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠
            if not img_files:
                img_files = [f for f in class_ref_dir.glob("*.*") 
                           if view_type in f.name.lower() and 
                           f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif']][:limit]
        else:
            # ‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ front ‡∏Å‡πà‡∏≠‡∏ô ‡∏´‡∏≤‡∏Å‡∏°‡∏µ
            front_files = list(class_ref_dir.glob("front_*.*"))[:limit]
            
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ front_ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ front ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠
            if not front_files:
                front_files = [f for f in class_ref_dir.glob("*.*") 
                             if "front" in f.name.lower() and 
                             f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif']][:limit]
            
            back_files = []
            
            # ‡∏ñ‡πâ‡∏≤‡∏£‡∏π‡∏õ front ‡πÑ‡∏°‡πà‡∏û‡∏≠‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô limit ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤‡∏£‡∏π‡∏õ back ‡∏°‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°
            if len(front_files) < limit:
                back_files = list(class_ref_dir.glob("back_*.*"))[:limit - len(front_files)]
                
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ back_ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ back ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠
                if not back_files:
                    back_files = [f for f in class_ref_dir.glob("*.*") 
                                if "back" in f.name.lower() and 
                                f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif']][:limit - len(front_files)]
                
            img_files = front_files + back_files
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        if not img_files:
            img_files = list(class_ref_dir.glob("*.*"))[:limit]
            img_files = [f for f in img_files if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif']]
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÄ‡∏õ‡πá‡∏ô base64
        for i, img_file in enumerate(img_files):
            try:
                with open(img_file, "rb") as f:
                    img_bytes = f.read()
                    img_b64 = base64.b64encode(img_bytes).decode('utf-8')
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö view_type ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
                    file_view_type = "unknown"
                    if "front" in img_file.name.lower():
                        file_view_type = "front"
                    elif "back" in img_file.name.lower():
                        file_view_type = "back"
                    
                    reference_images[f"ref_{i+1}"] = {
                        "image_b64": img_b64,
                        "filename": img_file.name,
                        "view_type": file_view_type,
                        "path": str(img_file.relative_to(REFERENCE_IMAGES_DIR.parent))
                    }
                    print(f"SUCCESS: Added reference image: {img_file.name} ({file_view_type})")
            except Exception as e:
                print(f"WARNING: Error processing reference image {img_file}: {e}")
                
        return reference_images
    except Exception as e:
        print(f"WARNING: Error getting reference images for {class_name}: {e}")
        return reference_images

@app.on_event("startup")
async def startup_event():
    """‡πÇ‡∏´‡∏•‡∏î model ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"""
    print("Starting Amulet-AI Backend with Real Model...")
    success = model_loader.initialize()
    if success:
        print("SUCCESS: Backend ready with Real AI Model!")
    else:
        print("WARNING: Backend started but Model may have issues")

@app.get("/")
async def root():
    return {
        "message": "Amulet-AI Backend with Real Trained Model",
        "status": "running",
        "model_loaded": model_loader.model is not None,
        "classes": len(model_loader.class_names),
        "version": "2.0.0"
    }

@app.get("/health")
async def health_check():
    model_info = model_loader.get_model_info()
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "ai_service_available": model_loader.model is not None,
        "model_status": "loaded" if model_loader.model is not None else "not_loaded",
        "device": str(model_loader.device),
        "classes": model_loader.class_names,
        "num_classes": len(model_loader.class_names),
        "endpoints": ["/predict", "/model-info", "/health", "/docs"]
    }

@app.get("/model-info")
async def get_model_info():
    """‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö model ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î"""
    model_info = model_loader.get_model_info()
    return {
        **model_info,
        "price_categories": list(PRICE_DATA.keys()),
        "total_price_ranges": len(PRICE_DATA),
        "api_version": "2.0.0",
        "features": [
            "Real AI Model",
            "Price Estimation", 
            "Market Recommendations",
            "Multi-class Classification",
            "Confidence Scoring"
        ]
    }

@app.post("/predict")
async def predict(
    front: UploadFile = File(..., description="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á"),
    back: UploadFile = File(None, description="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏±‡∏á‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)")
):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Real AI Model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ"""
    start_time = time.time()
    
    if model_loader.model is None:
        raise HTTPException(
            status_code=503, 
            detail="AI Model ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
        )
    
    try:
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤ (‡∏´‡∏•‡∏±‡∏Å)
        front_bytes = await front.read()
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏±‡∏á (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        back_bytes = None
        if back:
            back_bytes = await back.read()
            print(f"Processing front: {front.filename} ({len(front_bytes)} bytes) and back: {back.filename} ({len(back_bytes)} bytes)")
        else:
            print(f"Processing front only: {front.filename} ({len(front_bytes)} bytes)")
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Real AI Model
        prediction_result = model_loader.predict_image(front_bytes)
        
        if not prediction_result.get("success", False):
            raise HTTPException(
                status_code=400,
                detail=f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ: {prediction_result.get('error', 'Unknown error')}"
            )
        
        # ‡∏î‡∏∂‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏±‡∏Å
        top1 = prediction_result["top1"]
        predictions = prediction_result["predictions"]
        model_info = prediction_result.get("model_info", {})
        
        # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤
        valuation = estimate_price(top1["class_name"], top1["confidence"])
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏•‡∏≤‡∏î
        recommendations = generate_recommendations(top1["class_name"], valuation)
        
        # ‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á - ‡∏î‡πâ‡∏≤‡∏ô‡∏´‡∏ô‡πâ‡∏≤
        front_reference_images = get_reference_images(top1["class_name"], "front", 2)
        
        # ‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á - ‡∏î‡πâ‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏á
        back_reference_images = get_reference_images(top1["class_name"], "back", 2)
        
        # ‡∏£‡∏ß‡∏°‡∏£‡∏π‡∏õ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        reference_images = {**front_reference_images, **back_reference_images}
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏•‡∏¢ ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ view_type
        if not reference_images:
            reference_images = get_reference_images(top1["class_name"], limit=4)
        
        processing_time = time.time() - start_time
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô base64 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ
        front_b64 = base64.b64encode(front_bytes).decode('utf-8')
        back_b64 = None
        if back_bytes:
            back_b64 = base64.b64encode(back_bytes).decode('utf-8')
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á response ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        response = {
            "ai_mode": "real_trained_model",
            "model_info": {
                "name": "Amulet-AI Real Model",
                "architecture": model_info.get("architecture", "Deep Learning"),
                "classes": model_info.get("num_classes", len(model_loader.class_names)),
                "device": model_info.get("device", str(model_loader.device)),
                "training_data": "Thai Buddhist Amulet Dataset"
            },
            "processing_time": processing_time,
            "timestamp": datetime.now().isoformat(),
            "image_info": {
                "front": {
                    "filename": front.filename,
                    "size": len(front_bytes),
                    "format": "image",
                    "image_b64": front_b64
                },
                "back": {
                    "filename": back.filename if back else None,
                    "size": len(back_bytes) if back_bytes else 0,
                    "format": "image" if back_bytes else None,
                    "image_b64": back_b64
                } if back_bytes else None
            },
            "top1": top1,
            "topk": predictions,
            "valuation": valuation,
            "recommendations": recommendations,
            "reference_images": reference_images,
            "metadata": prediction_result.get("metadata", {})
        }
        
        print(f"SUCCESS: Prediction successful: {top1['class_name']} ({top1['confidence']:.2%}) in {processing_time:.2f}s")
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"ERROR: Prediction error: {str(e)}")
        raise HTTPException(
            status_code=500, 
            detail=f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {str(e)}"
        )

@app.post("/predict-batch")
async def predict_batch(files: list[UploadFile] = File(...)):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô"""
    if len(files) > 10:
        raise HTTPException(status_code=400, detail="‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 10 ‡∏£‡∏π‡∏õ")
    
    results = []
    
    for i, file in enumerate(files):
        try:
            file_bytes = await file.read()
            result = model_loader.predict_image(file_bytes)
            
            if result.get("success", False):
                results.append({
                    "index": i,
                    "filename": file.filename,
                    "prediction": result["top1"],
                    "confidence": result["top1"]["confidence"],
                    "success": True
                })
            else:
                results.append({
                    "index": i,
                    "filename": file.filename,
                    "error": result.get("error", "Unknown error"),
                    "success": False
                })
                
        except Exception as e:
            results.append({
                "index": i,
                "filename": file.filename,
                "error": str(e),
                "success": False
            })
    
    successful_predictions = sum(1 for r in results if r["success"])
    
    return {
        "total_files": len(files),
        "successful_predictions": successful_predictions,
        "failed_predictions": len(files) - successful_predictions,
        "results": results,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/classes")
async def get_classes():
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ classes ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    return {
        "classes": model_loader.class_names,
        "total": len(model_loader.class_names),
        "price_data_available": [cls for cls in model_loader.class_names if cls in PRICE_DATA]
    }

if __name__ == "__main__":
    import uvicorn
    print("Starting Amulet-AI Backend with Real Model...")
    uvicorn.run(app, host="127.0.0.1", port=8001)
