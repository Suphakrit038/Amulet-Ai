"""
üè∫ Amulet-AI Backend with Real Trained Model
API ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ AI Model ‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏ó‡∏ô Mock Data
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import io
import time
from datetime import datetime
import logging
import os
import sys
from pathlib import Path

# ‡πÄ‡∏û‡∏¥‡πà‡∏° backend path ‡πÄ‡∏û‡∏∑‡πà‡∏≠ import modules ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å root project
BACKEND_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(BACKEND_DIR))

try:
    # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡∏î‡∏π‡∏• models
    from models.real_model_loader import AmuletModelLoader
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á global instance
    model_loader = AmuletModelLoader()
except ImportError as e:
    print(f"‚ö†Ô∏è Import error: {e}")
    # Fallback ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
    class DummyModelLoader:
        def __init__(self):
            self.model = None
            self.class_names = ["dummy_class"]
            self.device = "cpu"
        def initialize(self): return False
        def get_model_info(self): return {"error": "Model not loaded"}
        def predict_image(self, image_bytes): return {"success": False, "error": "No model"}
    model_loader = DummyModelLoader()

app = FastAPI(
    title="Amulet-AI with Real Trained Model", 
    description="Backend API ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ AI Model ‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß",
    version="2.0.0"
)

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á)
PRICE_DATA = {
    "somdej_fatherguay": {"min": 15000, "avg": 45000, "max": 150000},
    "somdej_portrait_back": {"min": 18000, "avg": 55000, "max": 180000},
    "somdej_prok_bodhi": {"min": 25000, "avg": 75000, "max": 250000},
    "somdej_waek_man": {"min": 20000, "avg": 60000, "max": 200000},
    "wat_nong_e_duk": {"min": 8000, "avg": 22000, "max": 70000},
    "wat_nong_e_duk_misc": {"min": 5000, "avg": 15000, "max": 50000},
}

def estimate_price(class_name: str, confidence: float):
    """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡∏≤‡∏° class ‡πÅ‡∏•‡∏∞ confidence"""
    base_prices = PRICE_DATA.get(class_name, {"min": 5000, "avg": 15000, "max": 50000})
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡∏≤‡∏° confidence
    confidence_factor = max(0.4, min(1.3, confidence * 1.2))  # 40% - 130%
    
    estimated_prices = {
        "p05": int(base_prices["min"] * confidence_factor),
        "p50": int(base_prices["avg"] * confidence_factor),
        "p95": int(base_prices["max"] * confidence_factor),
        "confidence": "high" if confidence > 0.8 else "medium" if confidence > 0.6 else "low"
    }
    
    return estimated_prices

def generate_recommendations(class_name: str, price_range: dict):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏•‡∏≤‡∏î‡∏Ç‡∏≤‡∏¢"""
    recommendations = []
    
    # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
    if "somdej" in class_name.lower():
        recommendations = [
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
                "distance": 0,
                "rating": 4.5,
                "reason": f"‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏≤‡∏¢{class_name} ‡∏°‡∏µ‡∏ú‡∏π‡πâ‡∏™‡∏∞‡∏™‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á"
            },
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡∏à‡∏ï‡∏∏‡∏à‡∏±‡∏Å‡∏£ ‡∏ã.26",
                "distance": 12,
                "rating": 4.7,
                "reason": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏ú‡∏π‡πâ‡∏ã‡∏∑‡πâ‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏π‡∏á"
            },
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ö‡∏≤‡∏á‡πÅ‡∏Ñ",
                "distance": 18,
                "rating": 4.3,
                "reason": "‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏û‡∏£‡∏∞‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"
            }
        ]
    elif "nong_e_duk" in class_name:
        recommendations = [
            {
                "market": "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á MBK",
                "distance": 8,
                "rating": 4.2,
                "reason": "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏°‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢"
            },
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
                "distance": 0,
                "rating": 4.4,
                "reason": f"‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö{class_name} ‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå"
            },
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏ô‡∏±‡∏î‡πÄ‡∏™‡∏≤‡∏£‡πå-‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå ‡∏à‡∏ï‡∏∏‡∏à‡∏±‡∏Å‡∏£",
                "distance": 15,
                "rating": 4.6,
                "reason": "‡∏ú‡∏π‡πâ‡∏ã‡∏∑‡πâ‡∏≠‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏î‡∏µ"
            }
        ]
    else:
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        recommendations = [
            {
                "market": "‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
                "distance": 0,
                "rating": 4.3,
                "reason": "‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πà‡∏ß‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å"
            },
            {
                "market": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏≤‡∏´‡∏°‡∏ì‡πå",
                "distance": 10,
                "rating": 4.1,
                "reason": "‡∏ï‡∏•‡∏≤‡∏î‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô ‡∏ú‡∏π‡πâ‡∏ã‡∏∑‡πâ‡∏≠‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏î‡∏µ"
            },
            {
                "market": "‡∏£‡πâ‡∏≤‡∏ô‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡πà‡∏≤‡∏ô‡∏™‡∏µ‡∏•‡∏°",
                "distance": 12,
                "rating": 4.4,
                "reason": "‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏Ñ‡∏≤‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°"
            }
        ]
    
    return recommendations

@app.on_event("startup")
async def startup_event():
    """‡πÇ‡∏´‡∏•‡∏î model ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"""
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Amulet-AI Backend with Real Model...")
    success = model_loader.initialize()
    if success:
        print("‚úÖ Backend ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Real AI Model!")
    else:
        print("‚ö†Ô∏è Backend ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ï‡πà Model ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤")

@app.get("/")
async def root():
    return {
        "message": "üè∫ Amulet-AI Backend with Real Trained Model",
        "status": "running",
        "model_loaded": model_loader.model is not None,
        "classes": len(model_loader.class_names),
        "version": "2.0.0"
    }

@app.get("/health")
async def health_check():
    model_info = model_loader.get_model_info()
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "ai_service_available": model_loader.model is not None,
        "model_status": "loaded" if model_loader.model is not None else "not_loaded",
        "device": str(model_loader.device),
        "classes": model_loader.class_names,
        "num_classes": len(model_loader.class_names),
        "endpoints": ["/predict", "/model-info", "/health", "/docs"]
    }

@app.get("/model-info")
async def get_model_info():
    """‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö model ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î"""
    model_info = model_loader.get_model_info()
    return {
        **model_info,
        "price_categories": list(PRICE_DATA.keys()),
        "total_price_ranges": len(PRICE_DATA),
        "api_version": "2.0.0",
        "features": [
            "Real AI Model",
            "Price Estimation", 
            "Market Recommendations",
            "Multi-class Classification",
            "Confidence Scoring"
        ]
    }

@app.post("/predict")
async def predict(
    front: UploadFile = File(..., description="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á"),
    back: UploadFile = File(None, description="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏±‡∏á‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)")
):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Real AI Model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ"""
    start_time = time.time()
    
    if model_loader.model is None:
        raise HTTPException(
            status_code=503, 
            detail="AI Model ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
        )
    
    try:
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤ (‡∏´‡∏•‡∏±‡∏Å)
        front_bytes = await front.read()
        
        print(f"üì§ Processing: {front.filename} ({len(front_bytes)} bytes)")
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Real AI Model
        prediction_result = model_loader.predict_image(front_bytes)
        
        if not prediction_result.get("success", False):
            raise HTTPException(
                status_code=400,
                detail=f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ: {prediction_result.get('error', 'Unknown error')}"
            )
        
        # ‡∏î‡∏∂‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏±‡∏Å
        top1 = prediction_result["top1"]
        predictions = prediction_result["predictions"]
        model_info = prediction_result.get("model_info", {})
        
        # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤
        valuation = estimate_price(top1["class_name"], top1["confidence"])
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏•‡∏≤‡∏î
        recommendations = generate_recommendations(top1["class_name"], valuation)
        
        processing_time = time.time() - start_time
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á response ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        response = {
            "ai_mode": "real_trained_model",
            "model_info": {
                "name": "Amulet-AI Real Model",
                "architecture": model_info.get("architecture", "Deep Learning"),
                "classes": model_info.get("num_classes", len(model_loader.class_names)),
                "device": model_info.get("device", str(model_loader.device)),
                "training_data": "Thai Buddhist Amulet Dataset"
            },
            "processing_time": processing_time,
            "timestamp": datetime.now().isoformat(),
            "image_info": {
                "filename": front.filename,
                "size": len(front_bytes),
                "format": "image"
            },
            "top1": top1,
            "topk": predictions,
            "valuation": valuation,
            "recommendations": recommendations,
            "metadata": prediction_result.get("metadata", {})
        }
        
        print(f"‚úÖ Prediction successful: {top1['class_name']} ({top1['confidence']:.2%}) in {processing_time:.2f}s")
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"‚ùå Prediction error: {str(e)}")
        raise HTTPException(
            status_code=500, 
            detail=f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {str(e)}"
        )

@app.post("/predict-batch")
async def predict_batch(files: list[UploadFile] = File(...)):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô"""
    if len(files) > 10:
        raise HTTPException(status_code=400, detail="‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 10 ‡∏£‡∏π‡∏õ")
    
    results = []
    
    for i, file in enumerate(files):
        try:
            file_bytes = await file.read()
            result = model_loader.predict_image(file_bytes)
            
            if result.get("success", False):
                results.append({
                    "index": i,
                    "filename": file.filename,
                    "prediction": result["top1"],
                    "confidence": result["top1"]["confidence"],
                    "success": True
                })
            else:
                results.append({
                    "index": i,
                    "filename": file.filename,
                    "error": result.get("error", "Unknown error"),
                    "success": False
                })
                
        except Exception as e:
            results.append({
                "index": i,
                "filename": file.filename,
                "error": str(e),
                "success": False
            })
    
    successful_predictions = sum(1 for r in results if r["success"])
    
    return {
        "total_files": len(files),
        "successful_predictions": successful_predictions,
        "failed_predictions": len(files) - successful_predictions,
        "results": results,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/classes")
async def get_classes():
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ classes ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    return {
        "classes": model_loader.class_names,
        "total": len(model_loader.class_names),
        "price_data_available": [cls for cls in model_loader.class_names if cls in PRICE_DATA]
    }

if __name__ == "__main__":
    import uvicorn
    print("üè∫ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Amulet-AI Backend with Real Model...")
    uvicorn.run(app, host="127.0.0.1", port=8001)
