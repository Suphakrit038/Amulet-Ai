"""
üè∫ Amulet-AI Integrated API System
‡∏£‡∏∞‡∏ö‡∏ö API ‡∏£‡∏ß‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Amulet-AI ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Mock Data ‡πÅ‡∏•‡∏∞ Real AI Model
"""
import os
import sys
import time
import logging
import asyncio
import random
from typing import List, Dict, Optional, Tuple, Any
from pathlib import Path
from datetime import datetime
from contextlib import asynccontextmanager

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ path ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡∏î‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
BACKEND_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(BACKEND_DIR))

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ FastAPI components
try:
    from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks, Depends, Request
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.middleware.gzip import GZipMiddleware
    from fastapi.responses import JSONResponse
    from pydantic import BaseModel, Field
    FASTAPI_AVAILABLE = True
    logging.info("‚úÖ FastAPI imported successfully")
except ImportError as e:
    logging.warning(f"‚ö†Ô∏è FastAPI not available: {e}")
    logging.warning("Install with: pip install fastapi uvicorn python-multipart")
    FASTAPI_AVAILABLE = False
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á mock classes ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤
    class FastAPI:
        def __init__(self, *args, **kwargs): pass
        def get(self, *args, **kwargs): return lambda func: func
        def post(self, *args, **kwargs): return lambda func: func
        def add_middleware(self, *args, **kwargs): pass
    class UploadFile: pass
    class File: pass
    class HTTPException(Exception): pass
    class BackgroundTasks: pass
    class Depends: pass
    class Request: pass
    class CORSMiddleware: pass
    class GZipMiddleware: pass
    class JSONResponse: pass
    class BaseModel: pass
    Field = lambda *args, **kwargs: None

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Real Model Loader
try:
    from models.real_model_loader import AmuletModelLoader
    REAL_MODEL_AVAILABLE = True
    model_loader = AmuletModelLoader()
    logging.info("‚úÖ Real Model Loader imported successfully")
except ImportError as e:
    logging.warning(f"‚ö†Ô∏è Real Model Loader not available: {e}")
    REAL_MODEL_AVAILABLE = False
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á mock class
    class DummyModelLoader:
        def __init__(self):
            self.model = None
            self.class_names = ["dummy_class"]
            self.device = "cpu"
        def initialize(self): return False
        def get_model_info(self): return {"error": "Model not loaded"}
        def predict_image(self, image_bytes): return {"success": False, "error": "No model"}
    model_loader = DummyModelLoader()

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
try:
    from services.valuation import get_optimized_valuation, get_quantiles
    from services.recommend import get_optimized_recommendations
    from config.app_config import get_config
    SERVICES_AVAILABLE = True
    logging.info("‚úÖ Valuation and Recommendation services imported successfully")
except ImportError as e:
    logging.warning(f"‚ö†Ô∏è Services import error: {e}")
    SERVICES_AVAILABLE = False
    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏≥‡∏•‡∏≠‡∏á
    async def get_optimized_valuation(class_name, confidence, condition="good"):
        return {
            "p05": 5000, "p50": 25000, "p95": 75000,
            "confidence": "medium" if confidence > 0.5 else "low"
        }
    
    def get_quantiles(class_id):
        return {
            "p05": 5000, "p50": 25000, "p95": 75000,
            "confidence": "medium", "class_name": "unknown"
        }
    
    async def get_optimized_recommendations(class_name, valuation):
        return [
            {"name": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå", "distance": 0, "specialty": "‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ", "rating": 4.5},
            {"name": "‡∏ï‡∏•‡∏≤‡∏î‡∏ô‡∏±‡∏î‡∏û‡∏£‡∏∞", "distance": 10, "specialty": "‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡πà‡∏≤", "rating": 4.2}
        ]
    
    def get_config():
        return type('Config', (), {'debug': True, 'api': type('APIConfig', (), {'cors_origins': ["*"]})})()

# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô (‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ service)
PRICE_DATA = {
    "somdej_fatherguay": {"min": 15000, "avg": 45000, "max": 150000},
    "somdej_portrait_back": {"min": 18000, "avg": 55000, "max": 180000},
    "somdej_prok_bodhi": {"min": 25000, "avg": 75000, "max": 250000},
    "somdej_waek_man": {"min": 20000, "avg": 60000, "max": 200000},
    "somdej_lion_base": {"min": 12000, "avg": 35000, "max": 85000},
    "wat_nong_e_duk": {"min": 8000, "avg": 22000, "max": 70000},
    "wat_nong_e_duk_misc": {"min": 5000, "avg": 15000, "max": 50000},
}

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("amulet-api")

# ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
request_stats = {
    "total_requests": 0,
    "successful_predictions": 0,
    "failed_predictions": 0,
    "avg_response_time": 0.0,
    "uptime_start": time.time()
}

# Pydantic Models
class TopKItem(BaseModel):
    class_id: int = Field(..., description="Class ID")
    class_name: str = Field(..., description="Class name")
    confidence: float = Field(..., ge=0.0, le=1.0, description="Prediction confidence")

class Valuation(BaseModel):
    p05: float = Field(..., description="5th percentile price (THB)")
    p50: float = Field(..., description="Median price (THB)")
    p95: float = Field(..., description="95th percentile price (THB)")
    confidence: str = Field(..., description="Valuation confidence level")
    condition_factor: Optional[float] = Field(1.0, description="Condition adjustment factor")

class MarketRecommendation(BaseModel):
    name: str = Field(..., description="Market name")
    distance: float = Field(..., description="Distance in kilometers")
    specialty: str = Field(..., description="Market specialty")
    rating: Optional[float] = Field(None, ge=0.0, le=5.0, description="Market rating")
    estimated_price_range: Optional[str] = Field(None, description="Expected price range")

# App Lifecycle Management
@asynccontextmanager
async def lifespan(app: FastAPI):
    """‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏á‡∏à‡∏£‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏Ç‡∏≠‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô"""
    # Startup
    logger.info("üöÄ Starting Amulet-AI Integrated API Server...")
    
    # ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î Real AI Model ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if REAL_MODEL_AVAILABLE:
        success = model_loader.initialize()
        if success:
            logger.info("‚úÖ Real AI Model initialized successfully!")
        else:
            logger.warning("‚ö†Ô∏è Real AI Model initialization failed, will use simulated predictions")
    
    # App startup complete
    logger.info("üéâ API Server ready!")
    
    yield
    
    # Shutdown
    logger.info("üîÑ Shutting down Amulet-AI API Server...")
    logger.info("üëã Server shutdown complete")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á FastAPI App
app = FastAPI(
    title="Amulet-AI Integrated API",
    description="Advanced Thai Buddhist Amulet Recognition and Valuation System",
    version="2.0.0",
    lifespan=lifespan,
)

# ‡πÄ‡∏û‡∏¥‡πà‡∏° Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.add_middleware(GZipMiddleware, minimum_size=1000)

# Helper Functions
def estimate_price(class_name: str, confidence: float) -> Dict:
    """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô"""
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ service ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ service
    if SERVICES_AVAILABLE:
        try:
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö synchronous (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô synchronous)
            class_id = 0  # default
            # ‡πÅ‡∏õ‡∏•‡∏á class_name ‡πÄ‡∏õ‡πá‡∏ô class_id
            if "fatherguay" in class_name or "‡πÅ‡∏´‡∏ß‡∏Å‡∏°‡πà‡∏≤‡∏ô" in class_name:
                class_id = 0
            elif "prok_bodhi" in class_name or "‡∏õ‡∏£‡∏Å‡πÇ‡∏û‡∏ò‡∏¥‡πå" in class_name:
                class_id = 1
            elif "lion_base" in class_name or "‡∏ê‡∏≤‡∏ô‡∏™‡∏¥‡∏á‡∏´‡πå" in class_name:
                class_id = 2
            elif "nong_e_duk" in class_name or "‡∏ß‡∏±‡∏î‡∏´‡∏ô‡∏≠‡∏á‡∏≠‡∏µ‡∏î‡∏∏‡∏Å" in class_name:
                class_id = 3
            
            return get_quantiles(class_id)
        except Exception as e:
            logger.error(f"Error using service valuation: {e}")
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÅ‡∏ó‡∏ô
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ service ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏á‡πà‡∏≤‡∏¢‡πÜ
    base_prices = PRICE_DATA.get(class_name, {"min": 5000, "avg": 15000, "max": 50000})
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡∏≤‡∏° confidence
    confidence_factor = max(0.4, min(1.3, confidence * 1.2))  # 40% - 130%
    
    estimated_prices = {
        "p05": int(base_prices["min"] * confidence_factor),
        "p50": int(base_prices["avg"] * confidence_factor),
        "p95": int(base_prices["max"] * confidence_factor),
        "confidence": "high" if confidence > 0.8 else "medium" if confidence > 0.6 else "low"
    }
    
    return estimated_prices

def generate_recommendations(class_name: str, price_range: dict) -> List[Dict]:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏•‡∏≤‡∏î‡∏Ç‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô"""
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ service ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ service (‡πÅ‡∏ö‡∏ö async)
    if SERVICES_AVAILABLE:
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á event loop ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ async function ‡πÉ‡∏ô sync function)
            loop = asyncio.get_event_loop()
            return loop.run_until_complete(get_optimized_recommendations(class_name, price_range))
        except Exception as e:
            logger.error(f"Error using recommendation service: {e}")
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÅ‡∏ó‡∏ô
    
    recommendations = []
    
    # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
    if "somdej" in class_name.lower():
        recommendations = [
            {
                "name": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
                "distance": 0,
                "specialty": "‡∏û‡∏£‡∏∞‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢",
                "rating": 4.5,
                "estimated_price_range": f"‡∏ø{price_range['p05']:,} - ‡∏ø{price_range['p95']:,}"
            },
            {
                "name": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡∏à‡∏ï‡∏∏‡∏à‡∏±‡∏Å‡∏£ ‡∏ã.26",
                "distance": 12,
                "specialty": "‡∏û‡∏£‡∏∞‡πÇ‡∏ö‡∏£‡∏≤‡∏ì",
                "rating": 4.7,
                "estimated_price_range": f"‡∏ø{int(price_range['p50'] * 0.9):,} - ‡∏ø{int(price_range['p95'] * 1.1):,}"
            },
            {
                "name": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ö‡∏≤‡∏á‡πÅ‡∏Ñ",
                "distance": 18,
                "specialty": "‡∏û‡∏£‡∏∞‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞",
                "rating": 4.3,
                "estimated_price_range": f"‡∏ø{int(price_range['p50'] * 0.8):,} - ‡∏ø{int(price_range['p95'] * 1.2):,}"
            }
        ]
    elif "nong_e_duk" in class_name:
        recommendations = [
            {
                "name": "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á MBK",
                "distance": 8,
                "specialty": "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á",
                "rating": 4.2,
                "estimated_price_range": f"‡∏ø{int(price_range['p50'] * 0.9):,} - ‡∏ø{int(price_range['p95'] * 1.0):,}"
            },
            {
                "name": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏∞‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
                "distance": 0,
                "specialty": "‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
                "rating": 4.4,
                "estimated_price_range": f"‡∏ø{int(price_range['p50'] * 0.8):,} - ‡∏ø{int(price_range['p95'] * 1.1):,}"
            },
            {
                "name": "‡∏ï‡∏•‡∏≤‡∏î‡∏ô‡∏±‡∏î‡πÄ‡∏™‡∏≤‡∏£‡πå-‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå ‡∏à‡∏ï‡∏∏‡∏à‡∏±‡∏Å‡∏£",
                "distance": 15,
                "specialty": "‡∏ï‡∏•‡∏≤‡∏î‡∏ô‡∏±‡∏î‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ",
                "rating": 4.6,
                "estimated_price_range": f"‡∏ø{int(price_range['p50'] * 1.0):,} - ‡∏ø{int(price_range['p95'] * 1.2):,}"
            }
        ]
    else:
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        recommendations = [
            {
                "name": "‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
                "distance": 0,
                "specialty": "‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πà‡∏ß‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®",
                "rating": 4.3,
                "estimated_price_range": f"‡∏ø{int(price_range['p50'] * 0.9):,} - ‡∏ø{int(price_range['p95'] * 1.0):,}"
            },
            {
                "name": "‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏£‡∏≤‡∏´‡∏°‡∏ì‡πå",
                "distance": 10,
                "specialty": "‡∏ï‡∏•‡∏≤‡∏î‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô",
                "rating": 4.1,
                "estimated_price_range": f"‡∏ø{int(price_range['p50'] * 0.8):,} - ‡∏ø{int(price_range['p95'] * 0.9):,}"
            },
            {
                "name": "‡∏£‡πâ‡∏≤‡∏ô‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡πà‡∏≤‡∏ô‡∏™‡∏µ‡∏•‡∏°",
                "distance": 12,
                "specialty": "‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå",
                "rating": 4.4,
                "estimated_price_range": f"‡∏ø{int(price_range['p50'] * 1.0):,} - ‡∏ø{int(price_range['p95'] * 1.1):,}"
            }
        ]
    
    return recommendations

async def process_prediction(image_bytes, filename) -> Dict:
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Real Model ‡∏´‡∏£‡∏∑‡∏≠ Mock Data"""
    if REAL_MODEL_AVAILABLE and model_loader.model is not None:
        # ‡πÉ‡∏ä‡πâ Real AI Model
        prediction_result = model_loader.predict_image(image_bytes)
        
        if not prediction_result.get("success", False):
            raise HTTPException(
                status_code=400,
                detail=f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ: {prediction_result.get('error', 'Unknown error')}"
            )
        
        # ‡∏î‡∏∂‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏±‡∏Å
        top1 = prediction_result["top1"]
        predictions = prediction_result["predictions"]
        
        return {
            "ai_mode": "real_trained_model",
            "top1": top1,
            "predictions": predictions,
            "metadata": prediction_result.get("metadata", {})
        }
    else:
        # ‡πÉ‡∏ä‡πâ Mock Data
        # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏•‡∏≠‡∏°
        class_names = [
            "somdej_fatherguay", 
            "somdej_portrait_back", 
            "somdej_prok_bodhi",
            "somdej_waek_man", 
            "somdej_lion_base",
            "wat_nong_e_duk", 
            "wat_nong_e_duk_misc"
        ]
        
        # ‡∏™‡∏∏‡πà‡∏°‡∏Ñ‡∏•‡∏≤‡∏™‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô
        main_class = random.choice(class_names)
        main_confidence = random.uniform(0.6, 0.95)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á top-k predictions
        predictions = [
            {"class_name": main_class, "confidence": main_confidence, "class_id": class_names.index(main_class)}
        ]
        
        # ‡∏™‡∏∏‡πà‡∏°‡∏Ñ‡∏•‡∏≤‡∏™‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÄ‡∏û‡∏¥‡πà‡∏°
        remaining = 1.0 - main_confidence
        for i in range(4):
            other_class = random.choice([c for c in class_names if c != main_class])
            other_conf = remaining * (0.7 ** (i+1))
            predictions.append({
                "class_name": other_class, 
                "confidence": other_conf,
                "class_id": class_names.index(other_class)
            })
        
        return {
            "ai_mode": "simulated_prediction",
            "top1": predictions[0],
            "predictions": predictions,
            "metadata": {"simulation": True}
        }

def update_stats(success: bool, processing_time: float):
    """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"""
    request_stats["total_requests"] += 1
    if success:
        request_stats["successful_predictions"] += 1
    else:
        request_stats["failed_predictions"] += 1
    
    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
    total = request_stats["successful_predictions"] + request_stats["failed_predictions"]
    current_avg = request_stats["avg_response_time"]
    request_stats["avg_response_time"] = (current_avg * (total - 1) + processing_time) / total

# API Endpoints
@app.get("/")
async def root():
    """Root endpoint - ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ"""
    return {
        "message": "üè∫ Amulet-AI Integrated API",
        "status": "running",
        "model_loaded": REAL_MODEL_AVAILABLE and model_loader.model is not None,
        "services_available": SERVICES_AVAILABLE,
        "version": "2.0.0",
        "uptime": time.time() - request_stats["uptime_start"]
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    model_info = {}
    if REAL_MODEL_AVAILABLE:
        model_info = model_loader.get_model_info()
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "ai_service": {
            "available": REAL_MODEL_AVAILABLE,
            "model_loaded": REAL_MODEL_AVAILABLE and model_loader.model is not None,
            "device": model_info.get("device", "N/A"),
            "classes": len(model_info.get("classes", [])),
        },
        "valuation_service": {
            "available": SERVICES_AVAILABLE
        },
        "recommendation_service": {
            "available": SERVICES_AVAILABLE
        },
        "request_stats": {
            "total_requests": request_stats["total_requests"],
            "successful": request_stats["successful_predictions"],
            "failed": request_stats["failed_predictions"],
            "avg_response_time": request_stats["avg_response_time"]
        },
        "endpoints": ["/predict", "/model-info", "/health", "/system-status", "/docs"]
    }

@app.get("/model-info")
async def get_model_info():
    """‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö model ‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£"""
    model_info = {}
    if REAL_MODEL_AVAILABLE:
        model_info = model_loader.get_model_info()
    
    return {
        **model_info,
        "price_categories": list(PRICE_DATA.keys()),
        "total_price_ranges": len(PRICE_DATA),
        "api_version": "2.0.0",
        "features": [
            "AI Model" if REAL_MODEL_AVAILABLE else "Simulated AI",
            "Price Estimation", 
            "Market Recommendations",
            "Multi-class Classification"
        ]
    }

@app.post("/predict")
async def predict(
    front: UploadFile = File(..., description="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á"),
    back: Optional[UploadFile] = File(None, description="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏±‡∏á‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)")
):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"""
    start_time = time.time()
    
    if REAL_MODEL_AVAILABLE and model_loader.model is None:
        logger.warning("AI Model ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î")
    
    try:
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤ (‡∏´‡∏•‡∏±‡∏Å)
        front_bytes = await front.read()
        logger.info(f"Processing: {front.filename} ({len(front_bytes)} bytes)")
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        prediction_result = await process_prediction(front_bytes, front.filename)
        
        # ‡∏î‡∏∂‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏±‡∏Å
        top1 = prediction_result["top1"]
        predictions = prediction_result["predictions"]
        
        # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤
        valuation = estimate_price(top1["class_name"], top1["confidence"])
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏•‡∏≤‡∏î
        recommendations = generate_recommendations(top1["class_name"], valuation)
        
        processing_time = time.time() - start_time
        
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        update_stats(True, processing_time)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á response ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        response = {
            "ai_mode": prediction_result["ai_mode"],
            "model_info": {
                "name": "Amulet-AI Model" if REAL_MODEL_AVAILABLE else "Simulated Model",
                "real_model": REAL_MODEL_AVAILABLE and model_loader.model is not None,
            },
            "processing_time": processing_time,
            "timestamp": datetime.now().isoformat(),
            "image_info": {
                "filename": front.filename,
                "size": len(front_bytes),
                "format": "image"
            },
            "top1": top1,
            "topk": predictions,
            "valuation": valuation,
            "recommendations": recommendations,
            "metadata": prediction_result.get("metadata", {})
        }
        
        logger.info(f"Prediction successful: {top1['class_name']} ({top1['confidence']:.2f}) in {processing_time:.2f}s")
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        processing_time = time.time() - start_time
        logger.error(f"Prediction error: {str(e)}")
        
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        update_stats(False, processing_time)
        
        raise HTTPException(
            status_code=500, 
            detail=f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {str(e)}"
        )

@app.post("/predict-batch")
async def predict_batch(files: List[UploadFile] = File(...)):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô"""
    if len(files) > 10:
        raise HTTPException(status_code=400, detail="‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 10 ‡∏£‡∏π‡∏õ")
    
    results = []
    
    for i, file in enumerate(files):
        try:
            file_bytes = await file.read()
            prediction_result = await process_prediction(file_bytes, file.filename)
            
            # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢
            top1 = prediction_result["top1"]
            valuation = estimate_price(top1["class_name"], top1["confidence"])
            
            results.append({
                "index": i,
                "filename": file.filename,
                "prediction": top1,
                "valuation": valuation,
                "success": True
            })
            
        except Exception as e:
            results.append({
                "index": i,
                "filename": file.filename,
                "error": str(e),
                "success": False
            })
    
    successful_predictions = sum(1 for r in results if r.get("success", False))
    
    return {
        "total_files": len(files),
        "successful_predictions": successful_predictions,
        "failed_predictions": len(files) - successful_predictions,
        "results": results,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/classes")
async def get_classes():
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ classes ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    if REAL_MODEL_AVAILABLE and model_loader.model is not None:
        return {
            "classes": model_loader.class_names,
            "total": len(model_loader.class_names),
            "price_data_available": [cls for cls in model_loader.class_names if cls in PRICE_DATA]
        }
    else:
        # ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ model ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏≤‡∏Å PRICE_DATA
        return {
            "classes": list(PRICE_DATA.keys()),
            "total": len(PRICE_DATA),
            "price_data_available": list(PRICE_DATA.keys())
        }

@app.get("/system-status")
async def get_system_status():
    """‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡πÇ‡∏î‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
    uptime = time.time() - request_stats["uptime_start"]
    
    return {
        "status": "operational",
        "uptime": uptime,
        "uptime_formatted": f"{int(uptime // 86400)}d {int((uptime % 86400) // 3600)}h {int((uptime % 3600) // 60)}m {int(uptime % 60)}s",
        "ai_mode": {
            "real_model_available": REAL_MODEL_AVAILABLE,
            "model_loaded": REAL_MODEL_AVAILABLE and model_loader.model is not None,
            "using_simulation": not (REAL_MODEL_AVAILABLE and model_loader.model is not None)
        },
        "services": {
            "valuation_available": SERVICES_AVAILABLE,
            "recommendation_available": SERVICES_AVAILABLE
        },
        "performance": {
            "total_requests": request_stats["total_requests"],
            "successful_predictions": request_stats["successful_predictions"],
            "failed_predictions": request_stats["failed_predictions"],
            "success_rate": request_stats["successful_predictions"] / max(1, request_stats["total_requests"]),
            "avg_response_time": request_stats["avg_response_time"]
        },
        "timestamp": datetime.now().isoformat()
    }

# Error handlers
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    return JSONResponse(
        status_code=exc.status_code,
        content={"error": exc.detail}
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    logger.error(f"Unhandled exception: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={"error": f"Internal server error: {str(exc)}"}
    )

# Main function
if __name__ == "__main__":
    import uvicorn
    
    logger.info("üöÄ Starting Amulet-AI Integrated API Server...")
    if not FASTAPI_AVAILABLE:
        logger.error("‚ùå FastAPI is not available. Please install it with: pip install fastapi uvicorn python-multipart")
        sys.exit(1)
    
    host = "127.0.0.1"
    port = 8000
    
    logger.info(f"üåê Server will run at http://{host}:{port}")
    logger.info(f"üìö API Documentation: http://{host}:{port}/docs")
    
    uvicorn.run(app, host=host, port=port)
