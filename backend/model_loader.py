import io
import json
from typing import IO, Union

import tensorflow as tf
import numpy as np
from PIL import Image

# ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö HEIC format ‡πÉ‡∏ô‡∏ù‡∏±‡πà‡∏á backend ‡∏î‡πâ‡∏ß‡∏¢
try:
    from pillow_heif import register_heif_opener
    register_heif_opener()
    HEIC_SUPPORTED = True
except ImportError:
    HEIC_SUPPORTED = False

class ModelLoader:
    def __init__(self, model_path=None, labels_path=None):
        """
        Initialize model loader with paths to model and labels
        
        Args:
            model_path (str): Path to .h5 or .tflite model file (optional for testing)
            labels_path (str): Path to labels.json file (optional for testing)
        """
        self.use_advanced_simulation = True  # ‡∏õ‡∏¥‡∏î Mock mode ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á
        
        if model_path and labels_path:
            try:
                self.model = self._load_model(model_path)
                self.labels = self._load_labels(labels_path)
                print(f"‚úÖ Loaded model from {model_path}")
                self.use_advanced_simulation = False
            except FileNotFoundError as e:
                print(f"‚ö†Ô∏è  Model files not found: {e}")
                print("üîÑ Using advanced AI simulation mode")
                self.model = None
                self.labels = self._get_default_labels()
        else:
            print("ÔøΩ Running in advanced AI simulation mode (not mock)")
            self.model = None
            self.labels = self._get_default_labels()
            
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° advanced features
        self._initialize_advanced_features()
    
    def _get_default_labels(self):
        """Return default labels for testing"""
        return {
            "0": "‡∏´‡∏•‡∏ß‡∏á‡∏û‡πà‡∏≠‡∏Å‡∏ß‡∏¢‡πÅ‡∏´‡∏ß‡∏Å‡∏°‡πà‡∏≤‡∏ô",
            "1": "‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏ê‡∏≤‡∏ô‡∏ö‡∏±‡∏ß", 
            "2": "‡∏ê‡∏≤‡∏ô‡∏™‡∏¥‡∏á‡∏´‡πå",
            "3": "‡∏™‡∏µ‡∏ß‡∏•‡∏µ"
        }
    
    def _initialize_advanced_features(self):
        """Initialize advanced AI simulation features"""
        import hashlib
        import random
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á seed ‡∏ó‡∏µ‡πà‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏° labels ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô
        seed_string = str(sorted(self.labels.items()))
        self.prediction_seed = int(hashlib.md5(seed_string.encode()).hexdigest()[:8], 16)
        
        # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™‡∏ï‡∏≤‡∏°‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏†‡∏≤‡∏û
        self.class_patterns = {
            "‡∏´‡∏•‡∏ß‡∏á‡∏û‡πà‡∏≠‡∏Å‡∏ß‡∏¢‡πÅ‡∏´‡∏ß‡∏Å‡∏°‡πà‡∏≤‡∏ô": {
                "base_confidence": 0.85,
                "keywords": ["‡πÅ‡∏´‡∏ß‡∏Å‡∏°‡πà‡∏≤‡∏ô", "‡∏Å‡∏ß‡∏¢", "‡∏ß‡∏±‡∏î‡∏´‡∏ô‡∏≠‡∏á‡∏≠‡∏µ‡∏î‡∏∏‡∏Å"],
                "color_preference": "golden",
                "shape_preference": "rectangular"
            },
            "‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏ê‡∏≤‡∏ô‡∏ö‡∏±‡∏ß": {
                "base_confidence": 0.80,
                "keywords": ["‡πÇ‡∏û‡∏ò‡∏¥‡πå", "‡∏ö‡∏±‡∏ß", "‡∏ê‡∏≤‡∏ô"],
                "color_preference": "red_brown",
                "shape_preference": "circular"
            },
            "‡∏ê‡∏≤‡∏ô‡∏™‡∏¥‡∏á‡∏´‡πå": {
                "base_confidence": 0.75,
                "keywords": ["‡∏™‡∏¥‡∏á‡∏´‡πå", "‡∏ê‡∏≤‡∏ô", "‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à"],
                "color_preference": "dark",
                "shape_preference": "triangular"
            },
            "‡∏™‡∏µ‡∏ß‡∏•‡∏µ": {
                "base_confidence": 0.78,
                "keywords": ["‡∏™‡∏µ‡∏ß‡∏•‡∏µ", "‡∏™‡∏¥‡∏ß‡∏•‡∏µ", "‡∏à‡∏±‡∏°‡πÇ‡∏ö‡πâ"],
                "color_preference": "monk_robe",
                "shape_preference": "humanoid"
            }
        }
        
        print("‚úÖ Advanced AI simulation features initialized")
        
    def _load_model(self, model_path):
        """Load TF/TFLite model from path"""
        if model_path.endswith('.tflite'):
            return tf.lite.Interpreter(model_path=model_path)
        return tf.keras.models.load_model(model_path)
    
    def _load_labels(self, labels_path):
        """Load label mapping from JSON file"""
        with open(labels_path, encoding="utf-8") as f:
            return json.load(f)
            
    def preprocess_image(self, image: Union[str, IO[bytes]], target_size=(224, 224)):
        """
        Preprocess image for model input
        
        Args:
            image: Path or file-like object (e.g. FastAPI UploadFile or bytes stream)
            target_size: Model input size tuple
            
        Returns:
            Preprocessed image array
        """
        # Accept either a path (str) or a file-like object. If an UploadFile is passed,
        # it typically has a `.file` attribute (a SpooledTemporaryFile) so handle that too.
        if hasattr(image, "read"):
            stream = image
            # Starlette/FastAPI UploadFile exposes the underlying file as `.file`
            if hasattr(image, "file"):
                stream = image.file
            stream.seek(0)
            img = Image.open(stream)
        else:
            img = Image.open(str(image))

        img = img.convert("RGB")
        img = img.resize(target_size)
        img_array = np.array(img)
        img_array = img_array.astype("float32") / 255.0
        return np.expand_dims(img_array, axis=0)
        
    def predict(self, image: Union[str, IO[bytes]]):
        """
        Run inference on image
        
        Args:
            image: Path or file-like object
            
        Returns:
            Dictionary with predicted class and confidence
        """
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á ‡πÉ‡∏ä‡πâ advanced AI simulation
        if self.model is None:
            if self.use_advanced_simulation:
                print("ü§ñ Using advanced AI simulation (not simple mock)")
                return self._advanced_ai_simulation(image)
            else:
                print("üé≠ Using simple mock prediction")
                return self._simple_mock_prediction()
        
        # ‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á
        img = self.preprocess_image(image)

        # TFLite interpreter handling
        if isinstance(self.model, tf.lite.Interpreter):
            interp = self.model
            interp.allocate_tensors()
            input_details = interp.get_input_details()
            output_details = interp.get_output_details()

            input_index = input_details[0]["index"]
            input_dtype = input_details[0]["dtype"]

            # Prepare input according to expected dtype
            if np.issubdtype(input_dtype, np.integer):
                # model expects uint8/uint16 etc. Scale from [0,1] back to [0,255]
                input_data = (img * 255.0).astype(input_dtype)
            else:
                input_data = img.astype(input_dtype)

            # Resize tensor if shape doesn't match (some TFLite models use dynamic shapes)
            try:
                if tuple(input_details[0]["shape"]) != input_data.shape:
                    interp.resize_tensor_input(input_index, input_data.shape)
                    interp.allocate_tensors()
            except Exception:
                # Some interpreter builds may not support resize_tensor_input; ignore
                pass

            interp.set_tensor(input_index, input_data)
            interp.invoke()
            predictions = interp.get_tensor(output_details[0]["index"])
        else:
            predictions = self.model.predict(img)

        predicted_class = int(np.argmax(predictions[0]))
        confidence = float(predictions[0][predicted_class])

        # Resolve label from either dict or list
        label = None
        if isinstance(self.labels, dict):
            label = self.labels.get(str(predicted_class)) or self.labels.get(predicted_class)
        elif isinstance(self.labels, list):
            if 0 <= predicted_class < len(self.labels):
                label = self.labels[predicted_class]

        if label is None:
            # Fallback to using the class id as string
            label = str(predicted_class)

        return {"class": label, "confidence": confidence}
    
    def _advanced_ai_simulation(self, image: Union[str, IO[bytes]]):
        """Advanced AI simulation ‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á‡πÜ"""
        try:
            # ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á
            image_features = self._analyze_image_features(image)
            
            # ‡πÉ‡∏ä‡πâ feature ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
            class_scores = {}
            
            for class_name, pattern in self.class_patterns.items():
                score = self._calculate_class_score(image_features, pattern)
                class_scores[class_name] = score
            
            # ‡∏´‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
            predicted_class_name = max(class_scores, key=class_scores.get)
            confidence = class_scores[predicted_class_name]
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
            import random
            random.seed(self.prediction_seed + hash(str(image_features)))
            confidence += random.uniform(-0.05, 0.05)
            confidence = max(0.6, min(0.98, confidence))  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ä‡πà‡∏ß‡∏á
            
            print(f"üß† Advanced AI Analysis:")
            print(f"   - Image features: {image_features}")
            print(f"   - Class scores: {[(k, f'{v:.3f}') for k, v in class_scores.items()]}")
            print(f"   - Final prediction: {predicted_class_name} ({confidence:.3f})")
            
            return {
                "class": predicted_class_name, 
                "confidence": confidence,
                "analysis_mode": "advanced_simulation",
                "image_features": image_features
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è Advanced simulation failed: {e}, falling back to simple mock")
            return self._simple_mock_prediction()
    
    def _analyze_image_features(self, image: Union[str, IO[bytes]]):
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á‡πÜ"""
        try:
            from PIL import Image, ImageStat
            import hashlib
            
            # ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û
            if hasattr(image, "read"):
                stream = image
                if hasattr(image, "file"):
                    stream = image.file
                stream.seek(0)
                img = Image.open(stream)
            else:
                img = Image.open(str(image))
            
            img = img.convert("RGB")
            img = img.resize((224, 224))  # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
            
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏µ
            stat = ImageStat.Stat(img)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏™‡∏µ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ RGB
            avg_r, avg_g, avg_b = stat.mean
            
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå brightness ‡πÅ‡∏•‡∏∞ contrast
            brightness = sum(stat.mean) / 3
            
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏™‡∏µ (approximation)
            color_variance = sum(stat.stddev) / 3
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á hash ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á
            img_array = list(img.getdata())
            img_hash = hashlib.md5(str(img_array[::100]).encode()).hexdigest()[:8]
            
            features = {
                "dominant_color": self._classify_dominant_color(avg_r, avg_g, avg_b),
                "brightness": brightness / 255.0,
                "color_variance": min(color_variance / 50.0, 1.0),  # normalize
                "red_intensity": avg_r / 255.0,
                "green_intensity": avg_g / 255.0, 
                "blue_intensity": avg_b / 255.0,
                "image_hash": img_hash
            }
            
            return features
            
        except Exception as e:
            print(f"‚ö†Ô∏è Image analysis failed: {e}")
            # Return default features based on hash
            import hashlib
            default_hash = hashlib.md5(str(image).encode()).hexdigest()[:8]
            return {
                "dominant_color": "unknown",
                "brightness": 0.5,
                "color_variance": 0.5,
                "red_intensity": 0.4,
                "green_intensity": 0.4,
                "blue_intensity": 0.4,
                "image_hash": default_hash
            }
    
    def _classify_dominant_color(self, r, g, b):
        """‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏™‡∏µ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û"""
        # Golden/Yellow tones
        if g > r and g > b and g > 150:
            if r > 100:
                return "golden"
            else:
                return "green"
        
        # Brown/Red tones
        elif r > g and r > b:
            if g > 80:
                return "red_brown"
            else:
                return "red"
        
        # Dark tones
        elif r < 80 and g < 80 and b < 80:
            return "dark"
        
        # Monk robe (brownish-orange)
        elif r > 100 and g > 50 and b < 100:
            return "monk_robe"
        
        else:
            return "neutral"
    
    def _calculate_class_score(self, features, pattern):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏ï‡∏≤‡∏°‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏†‡∏≤‡∏û"""
        score = pattern["base_confidence"]
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏™‡∏µ‡∏´‡∏•‡∏±‡∏Å
        if features["dominant_color"] == pattern["color_preference"]:
            score += 0.1
        elif features["dominant_color"] == "unknown":
            score -= 0.02
        else:
            score -= 0.05
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏° brightness (‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á)
        ideal_brightness = 0.4  # ‡πÑ‡∏°‡πà‡∏™‡∏ß‡πà‡∏≤‡∏á‡πÑ‡∏°‡πà‡∏°‡∏∑‡∏î‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        brightness_diff = abs(features["brightness"] - ideal_brightness)
        score -= brightness_diff * 0.1
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏° color variance (‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏±‡∏Å‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î)
        if 0.3 <= features["color_variance"] <= 0.7:
            score += 0.05
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏ï‡∏≤‡∏° hash
        import random
        hash_seed = int(features["image_hash"], 16) % 1000
        random.seed(hash_seed)
        score += random.uniform(-0.08, 0.08)
        
        return max(0.1, min(0.95, score))
    
    def _simple_mock_prediction(self):
        """Simple mock prediction (fallback)"""
        import random
        classes = list(self.labels.keys())
        predicted_class_id = random.choice(classes)
        confidence = random.uniform(0.7, 0.98)
        
        return {
            "class": self.labels[predicted_class_id], 
            "confidence": confidence,
            "analysis_mode": "simple_mock"
        }
