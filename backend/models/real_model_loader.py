"""
üè∫ Amulet-AI Real Model Loader
‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô AI Model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡πâ‡∏ß
"""

import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import json
import os
import numpy as np
from typing import Dict, List, Tuple, Optional
import logging

class AmuletModelLoader:
    """Class ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ"""
    
    def __init__(self, model_dir: str = "ai_models"):
        self.model_dir = model_dir
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.class_names = []
        self.transform = None
        self.metadata = {}
        
        print(f"üè∫ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô AmuletModelLoader...")
        print(f"üì± Device: {self.device}")
        print(f"üìÇ Model directory: {self.model_dir}")
        
    def load_class_names(self) -> List[str]:
        """‡πÇ‡∏´‡∏•‡∏î‡∏ä‡∏∑‡πà‡∏≠ class ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå"""
        possible_files = [
            os.path.join(self.model_dir, "labels.json"),
            os.path.join(self.model_dir, "classes.json"),
            os.path.join(self.model_dir, "class_names.json"),
            "labels.json",
            "classes.json"
        ]
        
        for file_path in possible_files:
            if os.path.exists(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            self.class_names = data
                        elif isinstance(data, dict):
                            self.class_names = list(data.values())
                        print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î class names ‡∏à‡∏≤‡∏Å {file_path}")
                        print(f"üìã Classes: {self.class_names}")
                        return self.class_names
                except Exception as e:
                    print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô {file_path}: {e}")
        
        # Fallback class names ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ
        self.class_names = [
            "somdej-fatherguay",
            "‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡πÄ‡∏à‡πâ‡∏≤‡πÉ‡∏ô‡∏ß‡∏¥‡∏´‡∏≤‡∏£", 
            "‡∏û‡∏£‡∏∞‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏ê‡∏≤‡∏ô‡∏™‡∏¥‡∏á‡∏´‡πå",
            "‡∏û‡∏£‡∏∞‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏õ‡∏£‡∏∞‡∏ó‡∏≤‡∏ô‡∏û‡∏£ ‡∏û‡∏∏‡∏ó‡∏ò‡∏Å‡∏ß‡∏±‡∏Å",
            "‡∏û‡∏£‡∏∞‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏´‡∏•‡∏±‡∏á‡∏£‡∏π‡∏õ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô",
            "‡∏û‡∏£‡∏∞‡∏™‡∏£‡∏£‡∏Ñ‡πå",
            "‡∏û‡∏£‡∏∞‡∏™‡∏¥‡∏ß‡∏•‡∏µ", 
            "‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏¥‡∏°‡∏û‡πå‡∏õ‡∏£‡∏Å‡πÇ‡∏û‡∏ò‡∏¥‡πå 9 ‡πÉ‡∏ö",
            "‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡πÅ‡∏´‡∏ß‡∏Å‡∏°‡πà‡∏≤‡∏ô",
            "‡∏≠‡∏≠‡∏Å‡∏ß‡∏±‡∏î‡∏´‡∏ô‡∏≠‡∏á‡∏≠‡∏µ‡∏î‡∏∏‡∏Å"
        ]
        print("‚ö†Ô∏è ‡πÉ‡∏ä‡πâ class names ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
        print(f"üìã Classes: {len(self.class_names)} classes")
        return self.class_names
    
    def create_model_architecture(self, num_classes: int) -> nn.Module:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á model architecture ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô"""
        try:
            # ‡∏•‡∏≠‡∏á ResNet18 ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å (architecture ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢)
            model = models.resnet18(pretrained=False)
            model.fc = nn.Linear(model.fc.in_features, num_classes)
            print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á ResNet18 architecture ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {num_classes} classes")
            return model
        except Exception as e:
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á ResNet18: {e}")
            
            # Fallback ‡πÄ‡∏õ‡πá‡∏ô simple CNN
            class SimpleCNN(nn.Module):
                def __init__(self, num_classes):
                    super(SimpleCNN, self).__init__()
                    self.features = nn.Sequential(
                        nn.Conv2d(3, 64, 3, padding=1),
                        nn.ReLU(),
                        nn.MaxPool2d(2),
                        nn.Conv2d(64, 128, 3, padding=1),
                        nn.ReLU(),
                        nn.MaxPool2d(2),
                        nn.AdaptiveAvgPool2d(7)
                    )
                    self.classifier = nn.Sequential(
                        nn.Dropout(0.5),
                        nn.Linear(128 * 7 * 7, 512),
                        nn.ReLU(),
                        nn.Dropout(0.5),
                        nn.Linear(512, num_classes)
                    )
                
                def forward(self, x):
                    x = self.features(x)
                    x = x.view(x.size(0), -1)
                    x = self.classifier(x)
                    return x
            
            print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Simple CNN architecture ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {num_classes} classes")
            return SimpleCNN(num_classes)
    
    def load_trained_model(self) -> bool:
        """‡πÇ‡∏´‡∏•‡∏î model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ"""
        # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå model ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡πÄ‡∏û‡∏¥‡πà‡∏° path variants)
        model_paths = [
            # Path ‡∏à‡∏≤‡∏Å backend directory
            os.path.join("..", self.model_dir, "training_output", "step5_final_model.pth"),
            os.path.join("..", self.model_dir, "training_output", "ultra_simple_model.pth"),
            os.path.join("..", self.model_dir, "training_output", "emergency_model.pth"),
            os.path.join("..", self.model_dir, "training_output", "step5_checkpoint_epoch_3.pth"),
            os.path.join("..", self.model_dir, "training_output", "step5_checkpoint_epoch_2.pth"),
            # Path ‡∏õ‡∏Å‡∏ï‡∏¥
            os.path.join(self.model_dir, "training_output", "step5_final_model.pth"),
            os.path.join(self.model_dir, "training_output", "ultra_simple_model.pth"),
            os.path.join(self.model_dir, "training_output", "emergency_model.pth"),
            os.path.join(self.model_dir, "training_output", "step5_checkpoint_epoch_3.pth"),
            os.path.join(self.model_dir, "training_output", "step5_checkpoint_epoch_2.pth"),
            # Path ‡∏≠‡∏∑‡πà‡∏ô‡πÜ
            os.path.join(self.model_dir, "amulet_model.h5"),  # ‡πÑ‡∏ü‡∏•‡πå h5 ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
            os.path.join(self.model_dir, "somdej-fatherguay_best.h5")
        ]
        
        print(f"üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö model paths...")
        for model_path in model_paths:
            print(f"   üìÇ {model_path} -> {'‚úÖ' if os.path.exists(model_path) else '‚ùå'}")
            if os.path.exists(model_path):
                try:
                    print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î model ‡∏à‡∏≤‡∏Å {model_path}")
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå
                    file_size = os.path.getsize(model_path) / 1024 / 1024  # MB
                    print(f"üìä ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå: {file_size:.1f} MB")
                    
                    # ‡πÇ‡∏´‡∏•‡∏î checkpoint
                    checkpoint = torch.load(model_path, map_location=self.device)
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á checkpoint
                    if isinstance(checkpoint, dict):
                        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô dict ‡∏≠‡∏≤‡∏à‡∏°‡∏µ metadata
                        if 'model_state_dict' in checkpoint:
                            state_dict = checkpoint['model_state_dict']
                            if 'metadata' in checkpoint:
                                self.metadata = checkpoint['metadata']
                        elif 'state_dict' in checkpoint:
                            state_dict = checkpoint['state_dict']
                        else:
                            state_dict = checkpoint
                    else:
                        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô state_dict ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
                        state_dict = checkpoint
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á model ‡∏ï‡∏≤‡∏° architecture
                    num_classes = len(self.class_names)
                    self.model = self.create_model_architecture(num_classes)
                    
                    # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° load weights
                    try:
                        self.model.load_state_dict(state_dict, strict=True)
                        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î weights ‡πÅ‡∏ö‡∏ö strict ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                    except Exception as e:
                        print(f"‚ö†Ô∏è ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ö‡∏ö strict ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
                        try:
                            self.model.load_state_dict(state_dict, strict=False)
                            print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î weights ‡πÅ‡∏ö‡∏ö non-strict ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                        except Exception as e2:
                            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î weights: {e2}")
                            continue
                    
                    # ‡∏¢‡πâ‡∏≤‡∏¢ model ‡πÑ‡∏õ device ‡πÅ‡∏•‡∏∞‡πÄ‡∏ã‡πá‡∏ï evaluation mode
                    self.model.to(self.device)
                    self.model.eval()
                    
                    print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                    print(f"üéØ Model: {model_path}")
                    print(f"üìä Classes: {num_classes}")
                    print(f"üì± Device: {self.device}")
                    
                    return True
                    
                except Exception as e:
                    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î {model_path}: {e}")
                    continue
        
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö model file ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
        return False
    
    def setup_transform(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ image preprocessing transform"""
        # ‡∏Ñ‡πà‡∏≤ standard ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ImageNet pretrained models
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        input_size = 224
        
        self.transform = transforms.Compose([
            transforms.Resize((input_size, input_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std)
        ])
        
        print(f"üñºÔ∏è Transform setup: {input_size}x{input_size}, normalized")
    
    def predict_image(self, image_data) -> Dict:
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"""
        if self.model is None:
            raise ValueError("Model ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î")
        
        try:
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            if isinstance(image_data, bytes):
                import io
                image = Image.open(io.BytesIO(image_data))
            else:
                image = Image.open(image_data)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô RGB
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Apply transform
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                probs = probabilities.cpu().numpy()[0]
            
            # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            sorted_indices = np.argsort(probs)[::-1]
            
            results = {
                "success": True,
                "predictions": [],
                "top1": {
                    "class_name": self.class_names[sorted_indices[0]],
                    "confidence": float(probs[sorted_indices[0]]),
                    "class_id": int(sorted_indices[0])
                },
                "metadata": self.metadata,
                "model_info": {
                    "device": str(self.device),
                    "num_classes": len(self.class_names),
                    "architecture": "ResNet18-based" if hasattr(self.model, 'fc') else "Custom CNN"
                }
            }
            
            # Top-K results (5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å)
            for i, idx in enumerate(sorted_indices[:5]):
                results["predictions"].append({
                    "rank": i + 1,
                    "class_name": self.class_names[idx],
                    "confidence": float(probs[idx]),
                    "class_id": int(idx)
                })
            
            print(f"üéØ Prediction: {results['top1']['class_name']} ({results['top1']['confidence']:.2%})")
            
            return results
            
        except Exception as e:
            print(f"‚ùå Prediction error: {e}")
            return {
                "success": False,
                "error": str(e),
                "predictions": [],
                "top1": {"class_name": "Unknown", "confidence": 0.0}
            }
    
    def initialize(self) -> bool:
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        print("üè∫ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö Amulet-AI Real Model...")
        
        # 1. ‡πÇ‡∏´‡∏•‡∏î class names
        self.load_class_names()
        
        # 2. ‡πÇ‡∏´‡∏•‡∏î trained model
        if not self.load_trained_model():
            print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î model ‡πÑ‡∏î‡πâ")
            return False
        
        # 3. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ transform
        self.setup_transform()
        
        print("‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Real AI Model!")
        return True
    
    def get_model_info(self) -> Dict:
        """‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö model"""
        return {
            "model_loaded": self.model is not None,
            "classes": self.class_names,
            "num_classes": len(self.class_names),
            "device": str(self.device),
            "metadata": self.metadata
        }

# ‡∏™‡∏£‡πâ‡∏≤‡∏á global instance
model_loader = AmuletModelLoader()
