#!/usr/bin/env python3
"""
Simple test script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
"""
import os
import sys
import json
import joblib
import numpy as np
from pathlib import Path

def test_model_files():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
    print("üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
    
    required_files = [
        'trained_model/classifier.joblib',
        'trained_model/label_encoder.joblib', 
        'trained_model/scaler.joblib',
        'trained_model/pca.joblib',
        'trained_model/ood_detector.joblib',
        'trained_model/model_info.json',
        'ai_models/labels.json'
    ]
    
    all_files_exist = True
    for file_path in required_files:
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            print(f"‚úÖ {file_path} ({file_size:,} bytes)")
        else:
            print(f"‚ùå {file_path} - ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå")
            all_files_exist = False
    
    return all_files_exist

def test_model_loading():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    print("\nüîÑ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
    
    try:
        # ‡πÇ‡∏´‡∏•‡∏î labels
        with open('ai_models/labels.json', 'r', encoding='utf-8') as f:
            labels = json.load(f)
        print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î labels ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(labels)} ‡∏Ñ‡∏•‡∏≤‡∏™")
        
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• components
        classifier = joblib.load('trained_model/classifier.joblib')
        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î classifier ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        
        scaler = joblib.load('trained_model/scaler.joblib')
        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î scaler ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        
        label_encoder = joblib.load('trained_model/label_encoder.joblib')
        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î label_encoder ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        
        # ‡∏≠‡πà‡∏≤‡∏ô model info
        with open('trained_model/model_info.json', 'r', encoding='utf-8') as f:
            model_info = json.load(f)
        print(f"‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô: {model_info.get('model_version', 'Unknown')}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dataset_structure():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    print("\nüìÅ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    
    dataset_paths = [
        'organized_dataset',
        'organized_dataset/raw',
        'organized_dataset/processed', 
        'organized_dataset/augmented',
        'organized_dataset/splits',
        'organized_dataset/metadata'
    ]
    
    for path in dataset_paths:
        if os.path.exists(path):
            if os.path.isdir(path):
                file_count = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])
                dir_count = len([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))])
                print(f"‚úÖ {path} ({dir_count} ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå, {file_count} ‡πÑ‡∏ü‡∏•‡πå)")
            else:
                print(f"‚úÖ {path} (‡πÑ‡∏ü‡∏•‡πå)")
        else:
            print(f"‚ùå {path} - ‡πÑ‡∏°‡πà‡∏û‡∏ö")

def check_api_availability():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ API server ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    print("\nüåê ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏° API...")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå API
    api_files = [
        'api/main_api.py',
        'api/main_api_fast.py'
    ]
    
    for api_file in api_files:
        if os.path.exists(api_file):
            print(f"‚úÖ {api_file}")
        else:
            print(f"‚ùå {api_file} - ‡πÑ‡∏°‡πà‡∏û‡∏ö")

def show_project_summary():
    """‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå"""
    print("\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå:")
    print("=" * 50)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
    if os.path.exists('PHASE_COMPLETION_REPORT.md'):
        print("‚úÖ ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
        try:
            with open('PHASE_COMPLETION_REPORT.md', 'r', encoding='utf-8') as f:
                content = f.read()
                if 'PHASE 1' in content:
                    print("   ‚úÖ Phase 1: Dataset Organization")
                if 'PHASE 2' in content:
                    print("   ‚úÖ Phase 2: Data Preprocessing")
                if 'PHASE 3' in content:
                    print("   ‚úÖ Phase 3: Model Training")
        except:
            pass
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö trained_model_backup
    if os.path.exists('trained_model_backup'):
        print("‚úÖ ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
    if os.path.exists('trained_model/model_info.json'):
        try:
            with open('trained_model/model_info.json', 'r') as f:
                info = json.load(f)
                print(f"‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô: {info.get('model_version', 'Unknown')}")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
                if 'test_accuracy' in info:
                    print(f"   üìà ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: {info['test_accuracy']:.2%}")
                if 'validation_accuracy' in info:
                    print(f"   üìà ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (validation): {info['validation_accuracy']:.2%}")
                    
        except:
            print("‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    print("üöÄ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö Amulet-AI v3.0")
    print("=" * 50)
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model_files_ok = test_model_files()
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model_loading_ok = test_model_loading()
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    test_dataset_structure()
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API
    check_api_availability()
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ
    show_project_summary()
    
    print("\n" + "=" * 50)
    
    if model_files_ok and model_loading_ok:
        print("üéâ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
        print("üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
        print("   - ‡πÄ‡∏£‡∏¥‡πà‡∏° API: python api/main_api_fast.py")
        print("   - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Frontend: python -m streamlit run frontend/main_streamlit_app.py")
    else:
        print("‚ö†Ô∏è ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î")
    
    print("‚ú® ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

if __name__ == "__main__":
    main()