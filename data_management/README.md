# üì¶ Data Management System

**Complete data pipeline for Amulet-AI classification system**

---

## üìã Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Modules](#modules)
- [Usage Examples](#usage-examples)
- [Configuration](#configuration)
- [Best Practices](#best-practices)
- [Troubleshooting](#troubleshooting)

---

## üéØ Overview

Data Management System ‡πÄ‡∏õ‡πá‡∏ô pipeline ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Amulet-AI ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏±‡πâ‡∏á:

- **Data Augmentation**: MixUp, CutMix, RandAugment, RandomErasing
- **Preprocessing**: CLAHE, Denoising, Edge Enhancement
- **Quality Control**: Blur detection, Brightness/Contrast validation
- **Dataset Management**: PyTorch Dataset, Stratified sampling, Train/Val/Test splitting
- **Validation**: FID/KID metrics (coming soon in Phase 1.5)

### üèóÔ∏è Architecture

```
data_management/
‚îú‚îÄ‚îÄ augmentation/          # Data augmentation techniques
‚îÇ   ‚îú‚îÄ‚îÄ advanced_augmentation.py    # MixUp, CutMix, RandAugment
‚îÇ   ‚îî‚îÄ‚îÄ augmentation_pipeline.py    # Pipeline management
‚îú‚îÄ‚îÄ preprocessing/         # Image preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py          # Basic preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ advanced_processor.py       # CLAHE, denoising
‚îÇ   ‚îî‚îÄ‚îÄ quality_checker.py          # Quality validation
‚îú‚îÄ‚îÄ dataset/              # Dataset loading & splitting
‚îÇ   ‚îú‚îÄ‚îÄ dataset_loader.py           # PyTorch Dataset
‚îÇ   ‚îú‚îÄ‚îÄ sampler.py                  # Balanced sampling
‚îÇ   ‚îî‚îÄ‚îÄ splitter.py                 # Train/val/test split
‚îî‚îÄ‚îÄ examples/             # Usage examples
    ‚îú‚îÄ‚îÄ example_usage.py
    ‚îî‚îÄ‚îÄ complete_examples.py
```

---

## ‚ú® Features

### üé® Data Augmentation

#### **MixUp** (Zhang et al. 2017)
- Linear interpolation ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 2 images
- Beta distribution sampling (Œ±=0.2-0.4)
- Label smoothing effect

#### **CutMix** (Yun et al. 2019)
- Cut & paste rectangular regions
- Preserves localization ability
- More realistic than MixUp

#### **RandAugment** (Cubuk et al. 2020)
- 13 augmentation operations
- Automatic magnitude tuning
- Parameters: n=2 ops, m=9 magnitude

#### **RandomErasing** (Zhong et al. 2020)
- Random rectangular occlusion
- Robust to occlusion
- p=0.5, scale=(0.02, 0.33)

### üî¨ Advanced Preprocessing

#### **CLAHE** (Contrast Limited Adaptive Histogram Equalization)
- Adaptive contrast enhancement
- Preserves details in shadows/highlights
- clip_limit=2.0, tile_size=8x8

#### **Denoising**
- Non-local means (best for Gaussian noise)
- Bilateral filter (edge-preserving)
- Gaussian blur (fallback)

#### **Edge Enhancement**
- Unsharp masking
- Laplacian sharpening
- Detail enhancement

### üîç Quality Control

- **Blur Detection**: Laplacian variance (threshold=50)
- **Brightness Check**: [30, 225] range
- **Contrast Check**: std dev ‚â• 30
- **Resolution Check**: ‚â• 224x224
- **Overall Score**: 0-100 composite score

### üìä Dataset Management

- **AmuletDataset**: PyTorch Dataset with caching
- **FrontBackDataset**: Paired front/back images
- **Stratified Sampling**: Preserve class distribution
- **Weighted Sampling**: Balance class imbalance
- **K-Fold Cross-Validation**: 5-fold default

---

## üì¶ Installation

### Requirements

```bash
# Core dependencies
pip install torch torchvision numpy pillow scikit-learn

# Optional (for advanced features)
pip install opencv-python  # For CLAHE, denoising
pip install matplotlib     # For visualization
```

### Verify Installation

```python
from data_management import (
    create_pipeline_from_preset,
    create_artifact_preprocessor,
    AmuletDataset
)
print("‚úÖ Data Management System ready!")
```

---

## üöÄ Quick Start

### 1. Basic Augmentation

```python
from data_management.augmentation import create_pipeline_from_preset
from torch.utils.data import Dataset, DataLoader

# Create augmentation pipeline
pipeline = create_pipeline_from_preset('medium', batch_size=32)

# Use with your dataset
dataset = YourDataset(transform=pipeline.get_transform('train'))
loader = pipeline.create_dataloader(dataset, mode='train')

# Training loop
for images, labels_a, labels_b, lam in loader:
    outputs = model(images)
    loss = lam * criterion(outputs, labels_a) + \
           (1 - lam) * criterion(outputs, labels_b)
    loss.backward()
```

### 2. Preprocessing Pipeline

```python
from data_management.preprocessing import create_artifact_preprocessor
from PIL import Image

# Create preprocessor
preprocessor = create_artifact_preprocessor()

# Process image
image = Image.open("amulet.jpg")
enhanced = preprocessor(image)  # Returns PIL Image
```

### 3. Quality Check

```python
from data_management.preprocessing import create_strict_checker

# Create checker
checker = create_strict_checker()

# Check image quality
metrics = checker.check_quality("image.jpg")

if metrics.passed:
    print(f"‚úÖ Quality OK (score: {metrics.overall_score:.1f}/100)")
else:
    print(f"‚ùå Quality issues: {metrics.issues}")
```

### 4. Dataset Loading

```python
from data_management.dataset import create_amulet_dataset
from data_management.dataset import create_balanced_sampler

# Load dataset
train_dataset = create_amulet_dataset(
    root_dir="organized_dataset",
    split='train',
    transform=pipeline.get_transform('train')
)

# Create balanced sampler
labels = [label for _, label in train_dataset]
sampler = create_balanced_sampler(labels, strategy='weighted')

# Create DataLoader
loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)
```

### 5. Train/Val/Test Split

```python
from data_management.dataset import split_dataset_stratified

# Get labels
labels = [label for _, label in dataset]

# Split dataset (70/15/15)
train_idx, val_idx, test_idx = split_dataset_stratified(
    labels,
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15
)

# Use indices with Subset
from torch.utils.data import Subset
train_set = Subset(dataset, train_idx)
val_set = Subset(dataset, val_idx)
test_set = Subset(dataset, test_idx)
```

---

## üìö Modules

### 1. Augmentation (`data_management.augmentation`)

#### **Classes**
- `MixUpAugmentation`: MixUp implementation
- `CutMixAugmentation`: CutMix implementation
- `RandAugmentPipeline`: RandAugment with 13 operations
- `RandomErasingTransform`: Random erasing
- `AugmentationPipeline`: Complete pipeline manager

#### **Helper Functions**
- `create_pipeline_from_preset()`: Quick pipeline creation
- `create_training_augmentation()`: Training transforms
- `create_validation_transform()`: Validation transforms

#### **Preset Configurations**

| Preset | Use Case | Dataset Size | Augmentation |
|--------|----------|--------------|--------------|
| `minimal` | Inference/Testing | Any | None |
| `light` | Small datasets | 100-500 | Light |
| `medium` | Medium datasets | 500-2000 | **‚≠ê Recommended** |
| `heavy` | Large datasets | >2000 | Heavy |

### 2. Preprocessing (`data_management.preprocessing`)

#### **Basic Preprocessing**
- `ImageProcessor`: Resize, normalize, color conversion
- `BasicPreprocessor`: Basic pipeline with enhancements

#### **Advanced Preprocessing**
- `CLAHEProcessor`: Contrast enhancement
- `DenoisingProcessor`: Noise removal
- `EdgeEnhancer`: Edge sharpening
- `AdvancedPreprocessor`: Complete advanced pipeline

#### **Quality Checking**
- `BlurDetector`: Laplacian variance
- `BrightnessContrastChecker`: Brightness/contrast validation
- `ResolutionChecker`: Resolution validation
- `ImageQualityChecker`: Complete quality check

### 3. Dataset (`data_management.dataset`)

#### **Dataset Loaders**
- `AmuletDataset`: Standard PyTorch Dataset
- `FrontBackDataset`: Paired front/back images

#### **Samplers**
- `StratifiedSampler`: Stratified sampling
- `WeightedClassSampler`: Weighted class balancing
- `BalancedBatchSampler`: Balanced batches

#### **Splitters**
- `DatasetSplitter`: Train/val/test splitting
- `split_dataset_stratified()`: Helper function
- `analyze_distribution()`: Distribution analysis

---

## üéõÔ∏è Configuration

### Augmentation Presets

#### Light Preset
```python
config = {
    'rand_augment_n': 1,        # 1 operation
    'rand_augment_m': 5,        # Magnitude 5
    'random_erasing_p': 0.3,    # 30% probability
    'mixup_alpha': 0.0,         # Disabled
    'cutmix_alpha': 0.0,        # Disabled
}
```

#### Medium Preset (Recommended)
```python
config = {
    'rand_augment_n': 2,        # 2 operations
    'rand_augment_m': 9,        # Magnitude 9
    'random_erasing_p': 0.5,    # 50% probability
    'mixup_alpha': 0.2,         # MixUp enabled
    'cutmix_alpha': 1.0,        # CutMix enabled
}
```

#### Heavy Preset
```python
config = {
    'rand_augment_n': 3,        # 3 operations
    'rand_augment_m': 12,       # Magnitude 12
    'random_erasing_p': 0.7,    # 70% probability
    'mixup_alpha': 0.4,         # Strong MixUp
    'cutmix_alpha': 1.0,        # CutMix enabled
}
```

### Custom Configuration

```python
from data_management.augmentation import AugmentationPipeline

# Create custom config
custom_config = {
    'image_size': 256,
    'batch_size': 64,
    'rand_augment_n': 2,
    'rand_augment_m': 10,
    'random_erasing_p': 0.6,
    'mixup_alpha': 0.3,
    'cutmix_alpha': 1.2,
    'num_classes': 6,
    'num_workers': 8
}

# Create pipeline
pipeline = AugmentationPipeline(custom_config)
```

---

## üí° Best Practices

### 1. Dataset Size Recommendations

| Dataset Size | Preset | Reasoning |
|--------------|--------|-----------|
| < 500 images | `light` | Avoid overfitting |
| 500-2000 images | `medium` | Balanced augmentation |
| > 2000 images | `heavy` or `medium` | More data = more aug possible |

### 2. Quality Control Pipeline

```python
# Recommended quality check pipeline
checker = create_strict_checker()

# Check all images before training
good_images = []
bad_images = []

for img_path in all_images:
    metrics = checker.check_quality(img_path)
    
    if metrics.passed and metrics.overall_score >= 70:
        good_images.append(img_path)
    else:
        bad_images.append((img_path, metrics.issues))

print(f"‚úÖ Good: {len(good_images)}")
print(f"‚ùå Bad: {len(bad_images)}")
```

### 3. Preprocessing for Amulet Images

```python
# For cultural artifacts (inscriptions, patterns)
preprocessor = create_artifact_preprocessor()

# For medical/x-ray style images
from data_management.preprocessing import create_medical_preprocessor
preprocessor = create_medical_preprocessor()
```

### 4. Balanced Training

```python
# Get labels
labels = [dataset[i][1] for i in range(len(dataset))]

# Create weighted sampler
sampler = create_balanced_sampler(labels, strategy='weighted')

# Use in DataLoader
loader = DataLoader(
    dataset,
    batch_size=32,
    sampler=sampler,
    num_workers=4
)
```

---

## üêõ Troubleshooting

### Issue 1: OpenCV not installed

**Error**: `ImportError: OpenCV not available`

**Solution**:
```bash
pip install opencv-python
```

Or use fallback methods (Gaussian blur instead of NLM denoising)

### Issue 2: Out of memory with caching

**Error**: `CUDA out of memory` or RAM issues

**Solution**:
```python
# Disable image caching
dataset = AmuletDataset(root_dir="data", cache_images=False)

# Reduce batch size
pipeline = create_pipeline_from_preset('medium', batch_size=16)
```

### Issue 3: Imbalanced dataset

**Problem**: Some classes have very few samples

**Solution**:
```python
# Use weighted sampler
sampler = create_balanced_sampler(labels, strategy='weighted')

# Or oversample minority classes manually
from torch.utils.data import WeightedRandomSampler
```

### Issue 4: Slow data loading

**Problem**: Training is I/O bound

**Solution**:
```python
# Increase num_workers
loader = DataLoader(dataset, num_workers=8, pin_memory=True)

# Enable image caching (if RAM available)
dataset = AmuletDataset(root_dir="data", cache_images=True)

# Use prefetch_factor
loader = DataLoader(dataset, prefetch_factor=2)
```

---

## üìä Performance Benchmarks

### Augmentation Speed (RTX 3090, Batch=32)

| Preset | Time/Batch | Speedup |
|--------|------------|---------|
| `minimal` | 12ms | 1.0x |
| `light` | 45ms | 0.27x |
| `medium` | 78ms | 0.15x |
| `heavy` | 125ms | 0.10x |

### Quality Check Speed

| Operation | Time/Image | Notes |
|-----------|------------|-------|
| Blur detection | 2-5ms | OpenCV Laplacian |
| Brightness/Contrast | 1-2ms | PIL ImageStat |
| Full quality check | 5-10ms | All checks |

---

## üéØ Next Steps

### Phase 1 Complete! ‚úÖ

- [x] Data Augmentation (MixUp, CutMix, RandAugment)
- [x] Image Preprocessing (CLAHE, Denoising)
- [x] Quality Control (Blur, Brightness, Contrast)
- [x] Dataset Management (Loading, Sampling, Splitting)

### Phase 1.5: Validation (Optional)

- [ ] FID (Fr√©chet Inception Distance) calculation
- [ ] KID (Kernel Inception Distance) calculation
- [ ] Distribution visualization
- [ ] Expert review tools

### Phase 2: Transfer Learning (Next!)

- [ ] ResNet50, EfficientNet backbones
- [ ] Freeze/unfreeze strategy
- [ ] Multi-stage training
- [ ] Learning rate scheduling

---

## üìù Examples

See `examples/` directory for complete examples:

- `example_usage.py`: Basic augmentation examples
- `complete_examples.py`: Full pipeline examples

Run examples:
```bash
cd data_management
python examples/example_usage.py
python examples/complete_examples.py
```

---

## üìÑ License

Part of Amulet-AI project

**Author**: Amulet-AI Team  
**Date**: October 2025  
**Version**: 1.0 (Phase 1 Complete)

---

## üôè Acknowledgments

Research papers implemented:
- MixUp: Zhang et al. (2017)
- CutMix: Yun et al. (2019)
- RandAugment: Cubuk et al. (2020)
- RandomErasing: Zhong et al. (2020)

---

**Ready for Phase 2: Transfer Learning! üöÄ**
